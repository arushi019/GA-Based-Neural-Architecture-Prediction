{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arushi019/GA-Based-Neural-Architecture-Prediction/blob/master/GA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Vusyr-PTigdO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import time\n",
        "import torch.optim as optim\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TDAg61LXisgG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_sz=10\n",
        "epoch=10\n",
        "lr=0.01\n",
        "cache_cnn={}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tn9mfEdBiuOD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "48fca9fd-8ab7-4fd9-d5d6-e5a1dc8e8aa9"
      },
      "cell_type": "code",
      "source": [
        "transform=transforms.Compose([transforms.ToTensor()])\n",
        "train=torchvision.datasets.MNIST(root='',train=True,transform=transform,download=True)\n",
        "test=torchvision.datasets.MNIST(root='',train=False,transform=transform,download=True)\n",
        "n_train=500\n",
        "train_samp=SubsetRandomSampler(np.arange(n_train))\n",
        "n_val=100\n",
        "val_samp=SubsetRandomSampler(np.arange(n_train,n_train+n_val))\n",
        "n_test=100\n",
        "test_samp=SubsetRandomSampler(np.arange(n_test))\n",
        "train_loader=torch.utils.data.DataLoader(train,batch_size=batch_sz,sampler=train_samp,num_workers=2)\n",
        "test_loader=torch.utils.data.DataLoader(test,batch_size=batch_sz,sampler=test_samp,num_workers=2)\n",
        "val_loader=torch.utils.data.DataLoader(train,batch_size=batch_sz,sampler=val_samp,num_workers=2)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/9912422 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:00, 27977025.94it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 447313.80it/s]\n",
            "  1%|          | 16384/1648877 [00:00<00:11, 144154.84it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 7562435.47it/s]                            \n",
            "8192it [00:00, 189973.45it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Extracting MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4wIurgCMiz0Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def initialise_population(samples=10):\n",
        "  population=[]\n",
        "  for i in range(samples):\n",
        "    temp=customCNN(batch_sz)\n",
        "    population.append(temp) \n",
        "    #cache_cnn[temp.id]=1000000\n",
        "  return population"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uYsuo8b8i4J2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluate(net, batch_size=batch_sz, n_epochs=epoch, learning_rate=lr):\n",
        "    global train_loader,test_loader,val_loader\n",
        "    if cache_cnn[net.id]!=1000000:\n",
        "      return cache_cnn[net.id]\n",
        "    #Print all of the hyperparameters of the training iteration:\n",
        "    print(\"===== HYPERPARAMETERS =====\")\n",
        "    print(\"batch_size=\", batch_size)\n",
        "    print(\"epochs=\", n_epochs)\n",
        "    print(\"learning_rate=\", learning_rate)\n",
        "    print(\"=\" * 30)\n",
        "    \n",
        "    #Get training data\n",
        "    #train_loader = get_train_loader(batch_size)\n",
        "    n_batches = len(train_loader)\n",
        "    \n",
        "    #Create our loss and optimizer functions\n",
        "    #loss, optimizer = createLossAndOptimizer(net, learning_rate)\n",
        "    loss = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
        "    \n",
        "    #Time for printing\n",
        "    training_start_time = time.time()\n",
        "    \n",
        "    #Loop for n_epochs\n",
        "    for epoch in range(n_epochs):\n",
        "        \n",
        "        running_loss = 0.0\n",
        "        print_every = n_batches // 10\n",
        "        start_time = time.time()\n",
        "        total_train_loss = 0\n",
        "        \n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "            \n",
        "            #Get inputs\n",
        "            inputs, labels = data\n",
        "            \n",
        "            #Wrap them in a Variable object\n",
        "            inputs, labels = Variable(inputs), Variable(labels)\n",
        "            \n",
        "            #Set the parameter gradients to zero\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            #Forward pass, backward pass, optimize\n",
        "            outputs = net(inputs)\n",
        "            #print(outputs.shape,labels.shape)\n",
        "            loss_size = loss(outputs, labels)\n",
        "            loss_size.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            #Print statistics\n",
        "            running_loss += loss_size.item()\n",
        "            total_train_loss += loss_size.item()\n",
        "            \n",
        "            #Print every 10th batch of an epoch\n",
        "            if (i + 1) % (print_every + 1) == 0:\n",
        "                print(\"Epoch {}, {:d}% \\t train_loss: {:.2f} took: {:.2f}s\".format(\n",
        "                        epoch+1, int(100 * (i+1) / n_batches), running_loss / print_every, time.time() - start_time))\n",
        "                #Reset running loss and time\n",
        "                running_loss = 0.0\n",
        "                start_time = time.time()\n",
        "            \n",
        "        #At the end of the epoch, do a pass on the validation set\n",
        "        total_val_loss = 0\n",
        "        for inputs, labels in val_loader:\n",
        "            \n",
        "            #Wrap tensors in Variables\n",
        "            inputs, labels = Variable(inputs), Variable(labels)\n",
        "            \n",
        "            #Forward pass\n",
        "            val_outputs = net(inputs)\n",
        "            val_loss_size = loss(val_outputs, labels)\n",
        "            total_val_loss += val_loss_size.item()\n",
        "            \n",
        "        print(\"Validation loss = {:.2f}\".format(total_val_loss / len(val_loader)))\n",
        "        \n",
        "    print(\"Training finished, took {:.2f}s\".format(time.time() - training_start_time))\n",
        "    total_test_loss=0\n",
        "    for inputs,labels in test_loader:\n",
        "      inputs,labels=Variable(inputs),Variable(labels)\n",
        "      t_outp=net(inputs)\n",
        "      t_loss_size=loss(t_outp,labels)\n",
        "      total_test_loss+=t_loss_size.item()\n",
        "    cache_cnn[net.id]=total_test_loss/len(test_loader)\n",
        "    print(\"Testing Loss for model\",net.id,\":\",total_test_loss/len(test_loader))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ldSxMnx1i68-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def choose_best_ones(population):\n",
        "  scores=[]\n",
        "  for i in range(len(population)):\n",
        "    try:\n",
        "      evaluate(population[i])\n",
        "      #scores.append(cache_cnn[population[i].id])\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "    scores.append(cache_cnn[population[i].id])\n",
        "    #print(scores[-1])\n",
        "  indices=[i for i in range(len(population))]\n",
        "  l=len(population)/2\n",
        "  l1=len(indices)\n",
        "  while(l1>l):\n",
        "    i1=random.randint(0,l1-1)\n",
        "    i2=random.randint(0,l1-1)\n",
        "    if i1==i2:\n",
        "      if i1<l1-1:\n",
        "        i2=i1+1\n",
        "      else:\n",
        "        i2=i1-1\n",
        "    print(indices,i1,i2,l1)\n",
        "    if scores[indices[i1]]<scores[indices[i2]]:\n",
        "      indices.remove(indices[i2])\n",
        "    else:\n",
        "      indices.remove(indices[i1])\n",
        "    l1=l1-1\n",
        "  new_parents=[population[i] for i in indices]\n",
        "  return new_parents"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G1V8jmoSi-Ey",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_length(val):\n",
        "    if val==1 or val==4:\n",
        "      return 2\n",
        "    if val==2:\n",
        "      return 3\n",
        "    if val==3:\n",
        "      return 1\n",
        "def crossover(sample1,sample2):\n",
        "  i1=sample1.num\n",
        "  i2=sample2.num\n",
        "  n1=[int(i1/10),i1%10]\n",
        "  n2=[int(i2/10),i2%10]\n",
        "  n11=[n2[0],n1[1]]\n",
        "  n12=[n1[0],n2[1]]\n",
        "  print(n11,n12)\n",
        "  t1=customCNN(batch_sz,n11)\n",
        "  t2=customCNN(batch_sz,n12)\n",
        "  for i in range(get_length(n11[0])):\n",
        "    temp_param1=sample2.layers[i].named_parameters()\n",
        "    temp_param2=t1.layers[i].named_parameters()\n",
        "    d_param=dict(temp_param2)\n",
        "    for name1,p1 in temp_param1:\n",
        "      if name1 in d_param:\n",
        "        d_param[name1].data.copy_(p1.data)\n",
        "  for i in range(get_length(n12[0])):\n",
        "    temp_param1=sample1.layers[i].named_parameters()\n",
        "    temp_param2=t2.layers[i].named_parameters()\n",
        "    d_param=dict(temp_param2)\n",
        "    for name1,p1 in temp_param1:\n",
        "      if name1 in d_param:\n",
        "        d_param[name1].data.copy_(p1.data)\n",
        "  return (t1,t2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nwe4V5lcjAlO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_children(population):\n",
        "  temp=[]\n",
        "  for i in range(0,len(population)-1,2):\n",
        "    (t1,t2)=crossover(population[i],population[i+1])\n",
        "    temp.append(t1)\n",
        "    temp.append(t2)\n",
        "  return temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "41wtTotvjDQb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class customCNN(nn.Module):\n",
        "  #                                               k x s x s         \n",
        "  #block 1: conv2d+avgPool                       6 x s/2 x s/2            \n",
        "  #block 2: conv2d+avgPool+dropOut               7 x s/2 x s/2            \n",
        "  #block 3: reshape+linear+reshape               (1,k*s*s)->64->(1*32*32)\n",
        "  #block 4: reshape+linear+dropOut+reshape       (1,k*s*s)->64->(1*32*32)\n",
        "  #reshape+linear layer                          (1,k*s*s)->10\n",
        "  def __init__(self,batch_sze,temp_v=None):\n",
        "    super(customCNN,self).__init__()\n",
        "    self.v=[0,0]\n",
        "    if temp_v!=None:\n",
        "      self.v[0]=temp_v[0]\n",
        "      self.v[1]=temp_v[1]\n",
        "    else:\n",
        "      self.v[0]=np.random.randint(1,5)\n",
        "      self.v[1]=np.random.randint(1,5)\n",
        "    self.num=self.v[0]*10+self.v[1]\n",
        "    self.id=time.time()\n",
        "    cache_cnn[self.id]=1000000\n",
        "    self.layers=[]\n",
        "    self.batch_size=batch_sze\n",
        "    k=self.batch_size\n",
        "    s=28\n",
        "    for i in range(2):\n",
        "      val=0\n",
        "      if self.v[i]==1:\n",
        "        val=self.block1(k,s)\n",
        "      if self.v[i]==2:\n",
        "        val=self.block2(k,s)\n",
        "      if self.v[i]==3:\n",
        "        val=self.block3(k,s)\n",
        "      if self.v[i]==4:\n",
        "        val=self.block4(k,s)\n",
        "      k=val[1]\n",
        "      s=val[2]\n",
        "      print(k,s)\n",
        "      for j in range(len(val[0])):\n",
        "        self.layers.append(val[0][j])\n",
        "    temp_layer=nn.Linear(k*s*s,10*k)\n",
        "    self.layers.append(temp_layer)\n",
        "    self.layers=nn.ModuleList(self.layers)\n",
        "    print(self.layers)\n",
        "  def get_length(val):\n",
        "    if val==1 or val==4:\n",
        "      return 2\n",
        "    if val==2:\n",
        "      return 3\n",
        "    if val==3:\n",
        "      return 1\n",
        "  def block1(self,k,s):\n",
        "    l1=nn.Conv2d(k,6*k,kernel_size=3,stride=1,padding=1)\n",
        "    l2=nn.AvgPool2d(kernel_size=2,stride=2)\n",
        "    return ([l1,l2],6*k,int(s/2))\n",
        "  def block2(self,k,s):\n",
        "    l1=nn.Conv2d(k,7*k,kernel_size=3,stride=1,padding=1)\n",
        "    l2=nn.AvgPool2d(kernel_size=2,stride=2)\n",
        "    l3=nn.Dropout(p=0.5)\n",
        "    return ([l1,l2,l3],7*k,int(s/2))\n",
        "  def block3(self,k,s):\n",
        "    #reshape in forward function\n",
        "    l1=nn.Linear(k*s*s,64*k)\n",
        "    #reshape \n",
        "    return ([l1],k,8)\n",
        "  def block4(self,k,s):\n",
        "    #reshape\n",
        "    l1=nn.Linear(k*s*s,64*k)\n",
        "    l2=nn.Dropout(p=0.4)\n",
        "    #reshape\n",
        "    return ([l1,l2],k,8)\n",
        "  def ps_forward(self,x,val,index):\n",
        "    #print(x.shape)\n",
        "    if val==1:\n",
        "      x=x.view(1,self.layers[index].in_channels,x.shape[2],-1)\n",
        "      x1=F.relu(self.layers[index](x))\n",
        "      x2=self.layers[index+1](x1)\n",
        "      return (x2,index+2)\n",
        "    if val==2:\n",
        "      x=x.view(1,self.layers[index].in_channels,x.shape[2],-1)\n",
        "      x1=F.relu(self.layers[index](x))\n",
        "      x2=self.layers[index+1](x1)\n",
        "      x3=self.layers[index+2](x2)\n",
        "      return (x3,index+3)\n",
        "    if val==3:\n",
        "      x1=x.view(1,-1)\n",
        "      x2=self.layers[index](x1)\n",
        "      x3=x2.view(self.batch_size,8,-1)\n",
        "      return (x3,index+1)\n",
        "    if val==4:\n",
        "      x1=x.view(1,-1)\n",
        "      x2=self.layers[index](x1)\n",
        "      x2=x2.view(1,-1)\n",
        "      x3=self.layers[index+1](x2)\n",
        "      x4=x3.view(self.batch_size,8,-1)\n",
        "      return (x4,index+2)\n",
        "  def forward(self,x):\n",
        "    pt=0\n",
        "    #x=x.view(1,1,x.shape[2],-1)\n",
        "    #print(x.shape)\n",
        "    for i in range(2):\n",
        "      x,pt=self.ps_forward(x,self.v[i],pt)\n",
        "      #print(x.shape)\n",
        "    x=x.view(1,-1)\n",
        "    x1=self.layers[pt](x)\n",
        "    x1=x1.view(self.batch_size,-1)\n",
        "    #x1=F.log_softmax(x1,dim=1)\n",
        "    return x1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CtVRB-AyU-x1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def best_result(population,num_epochs=100,converge=2):\n",
        "  scores=[]\n",
        "  for i in range(len(population)):\n",
        "    try:\n",
        "      evaluate(population[i])\n",
        "      scores.append(cache_cnn[population[i].id])\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "  it=0\n",
        "  diff=max(scores)-min(scores)\n",
        "  curr=population\n",
        "  while it<num_epochs and diff>converge:\n",
        "    curr=get_new_population(curr)\n",
        "    scores=[]\n",
        "    for i in range(len(population)):\n",
        "      try:\n",
        "        evaluate(population[i])\n",
        "        scores.append(cache_cnn[population[i].id])\n",
        "      except Exception as e:\n",
        "        print(e)\n",
        "    #print(scores)\n",
        "    diff=max(scores)-min(scores)\n",
        "    it+=1\n",
        "  ind=scores.index(min(scores))\n",
        "  return curr[ind]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DTuvKW5dXmQq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_new_population(current):\n",
        "  children=get_children(current)\n",
        "  new_p=current+children\n",
        "  #for i in range(len(new_p)):\n",
        "  #  new_p[i]=mutation(new_p[i])\n",
        "  new_p=choose_best_ones(new_p)\n",
        "  return new_p"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nv2oC-nIjKyM",
        "colab_type": "code",
        "outputId": "26a92d17-ffa0-49f3-a62f-03719bf615b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 25279
        }
      },
      "cell_type": "code",
      "source": [
        "p=initialise_population(samples=8)\n",
        "print(p)\n",
        "#scores=[evaluate(i) for i in p]\n",
        "scores=[]\n",
        "for i in range(len(p)):\n",
        "  try:\n",
        "    evaluate(p[i])\n",
        "    scores.append(cache_cnn[p[i].id])\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    \n",
        "#print(scores)\n",
        "sample=best_result(p,num_epochs=20,converge=0.005)\n",
        "print(sample,evaluate(sample))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 8\n",
            "70 4\n",
            "ModuleList(\n",
            "  (0): Linear(in_features=7840, out_features=640, bias=True)\n",
            "  (1): Conv2d(10, 70, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (3): Dropout(p=0.5)\n",
            "  (4): Linear(in_features=1120, out_features=700, bias=True)\n",
            ")\n",
            "10 8\n",
            "70 4\n",
            "ModuleList(\n",
            "  (0): Linear(in_features=7840, out_features=640, bias=True)\n",
            "  (1): Dropout(p=0.4)\n",
            "  (2): Conv2d(10, 70, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (3): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (4): Dropout(p=0.5)\n",
            "  (5): Linear(in_features=1120, out_features=700, bias=True)\n",
            ")\n",
            "60 14\n",
            "60 8\n",
            "ModuleList(\n",
            "  (0): Conv2d(10, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (2): Linear(in_features=11760, out_features=3840, bias=True)\n",
            "  (3): Linear(in_features=3840, out_features=600, bias=True)\n",
            ")\n",
            "10 8\n",
            "60 4\n",
            "ModuleList(\n",
            "  (0): Linear(in_features=7840, out_features=640, bias=True)\n",
            "  (1): Conv2d(10, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (3): Linear(in_features=960, out_features=600, bias=True)\n",
            ")\n",
            "70 14\n",
            "70 8\n",
            "ModuleList(\n",
            "  (0): Conv2d(10, 70, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (2): Dropout(p=0.5)\n",
            "  (3): Linear(in_features=13720, out_features=4480, bias=True)\n",
            "  (4): Dropout(p=0.4)\n",
            "  (5): Linear(in_features=4480, out_features=700, bias=True)\n",
            ")\n",
            "70 14\n",
            "70 8\n",
            "ModuleList(\n",
            "  (0): Conv2d(10, 70, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (2): Dropout(p=0.5)\n",
            "  (3): Linear(in_features=13720, out_features=4480, bias=True)\n",
            "  (4): Dropout(p=0.4)\n",
            "  (5): Linear(in_features=4480, out_features=700, bias=True)\n",
            ")\n",
            "60 14\n",
            "60 8\n",
            "ModuleList(\n",
            "  (0): Conv2d(10, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (2): Linear(in_features=11760, out_features=3840, bias=True)\n",
            "  (3): Linear(in_features=3840, out_features=600, bias=True)\n",
            ")\n",
            "10 8\n",
            "10 8\n",
            "ModuleList(\n",
            "  (0): Linear(in_features=7840, out_features=640, bias=True)\n",
            "  (1): Linear(in_features=640, out_features=640, bias=True)\n",
            "  (2): Dropout(p=0.4)\n",
            "  (3): Linear(in_features=640, out_features=100, bias=True)\n",
            ")\n",
            "[customCNN(\n",
            "  (layers): ModuleList(\n",
            "    (0): Linear(in_features=7840, out_features=640, bias=True)\n",
            "    (1): Conv2d(10, 70, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    (3): Dropout(p=0.5)\n",
            "    (4): Linear(in_features=1120, out_features=700, bias=True)\n",
            "  )\n",
            "), customCNN(\n",
            "  (layers): ModuleList(\n",
            "    (0): Linear(in_features=7840, out_features=640, bias=True)\n",
            "    (1): Dropout(p=0.4)\n",
            "    (2): Conv2d(10, 70, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    (4): Dropout(p=0.5)\n",
            "    (5): Linear(in_features=1120, out_features=700, bias=True)\n",
            "  )\n",
            "), customCNN(\n",
            "  (layers): ModuleList(\n",
            "    (0): Conv2d(10, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    (2): Linear(in_features=11760, out_features=3840, bias=True)\n",
            "    (3): Linear(in_features=3840, out_features=600, bias=True)\n",
            "  )\n",
            "), customCNN(\n",
            "  (layers): ModuleList(\n",
            "    (0): Linear(in_features=7840, out_features=640, bias=True)\n",
            "    (1): Conv2d(10, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    (3): Linear(in_features=960, out_features=600, bias=True)\n",
            "  )\n",
            "), customCNN(\n",
            "  (layers): ModuleList(\n",
            "    (0): Conv2d(10, 70, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    (2): Dropout(p=0.5)\n",
            "    (3): Linear(in_features=13720, out_features=4480, bias=True)\n",
            "    (4): Dropout(p=0.4)\n",
            "    (5): Linear(in_features=4480, out_features=700, bias=True)\n",
            "  )\n",
            "), customCNN(\n",
            "  (layers): ModuleList(\n",
            "    (0): Conv2d(10, 70, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    (2): Dropout(p=0.5)\n",
            "    (3): Linear(in_features=13720, out_features=4480, bias=True)\n",
            "    (4): Dropout(p=0.4)\n",
            "    (5): Linear(in_features=4480, out_features=700, bias=True)\n",
            "  )\n",
            "), customCNN(\n",
            "  (layers): ModuleList(\n",
            "    (0): Conv2d(10, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    (2): Linear(in_features=11760, out_features=3840, bias=True)\n",
            "    (3): Linear(in_features=3840, out_features=600, bias=True)\n",
            "  )\n",
            "), customCNN(\n",
            "  (layers): ModuleList(\n",
            "    (0): Linear(in_features=7840, out_features=640, bias=True)\n",
            "    (1): Linear(in_features=640, out_features=640, bias=True)\n",
            "    (2): Dropout(p=0.4)\n",
            "    (3): Linear(in_features=640, out_features=100, bias=True)\n",
            "  )\n",
            ")]\n",
            "===== HYPERPARAMETERS =====\n",
            "batch_size= 10\n",
            "epochs= 10\n",
            "learning_rate= 0.01\n",
            "==============================\n",
            "Epoch 1, 12% \t train_loss: 10.22 took: 0.74s\n",
            "Epoch 1, 24% \t train_loss: 5.22 took: 0.42s\n",
            "Epoch 1, 36% \t train_loss: 4.93 took: 0.42s\n",
            "Epoch 1, 48% \t train_loss: 4.28 took: 0.41s\n",
            "Epoch 1, 60% \t train_loss: 4.31 took: 0.41s\n",
            "Epoch 1, 72% \t train_loss: 4.35 took: 0.41s\n",
            "Epoch 1, 84% \t train_loss: 4.07 took: 0.43s\n",
            "Epoch 1, 96% \t train_loss: 4.50 took: 0.42s\n",
            "Validation loss = 3.15\n",
            "Epoch 2, 12% \t train_loss: 4.07 took: 0.56s\n",
            "Epoch 2, 24% \t train_loss: 4.10 took: 0.42s\n",
            "Epoch 2, 36% \t train_loss: 3.96 took: 0.41s\n",
            "Epoch 2, 48% \t train_loss: 3.93 took: 0.42s\n",
            "Epoch 2, 60% \t train_loss: 3.92 took: 0.41s\n",
            "Epoch 2, 72% \t train_loss: 3.67 took: 0.42s\n",
            "Epoch 2, 84% \t train_loss: 3.59 took: 0.41s\n",
            "Epoch 2, 96% \t train_loss: 3.62 took: 0.44s\n",
            "Validation loss = 3.25\n",
            "Epoch 3, 12% \t train_loss: 3.92 took: 0.54s\n",
            "Epoch 3, 24% \t train_loss: 3.53 took: 0.42s\n",
            "Epoch 3, 36% \t train_loss: 3.53 took: 0.41s\n",
            "Epoch 3, 48% \t train_loss: 3.78 took: 0.42s\n",
            "Epoch 3, 60% \t train_loss: 3.84 took: 0.41s\n",
            "Epoch 3, 72% \t train_loss: 3.89 took: 0.41s\n",
            "Epoch 3, 84% \t train_loss: 3.75 took: 0.42s\n",
            "Epoch 3, 96% \t train_loss: 3.37 took: 0.41s\n",
            "Validation loss = 2.81\n",
            "Epoch 4, 12% \t train_loss: 4.07 took: 0.55s\n",
            "Epoch 4, 24% \t train_loss: 3.43 took: 0.42s\n",
            "Epoch 4, 36% \t train_loss: 3.37 took: 0.41s\n",
            "Epoch 4, 48% \t train_loss: 2.98 took: 0.41s\n",
            "Epoch 4, 60% \t train_loss: 3.42 took: 0.42s\n",
            "Epoch 4, 72% \t train_loss: 3.12 took: 0.42s\n",
            "Epoch 4, 84% \t train_loss: 3.40 took: 0.42s\n",
            "Epoch 4, 96% \t train_loss: 3.31 took: 0.41s\n",
            "Validation loss = 2.65\n",
            "Epoch 5, 12% \t train_loss: 3.29 took: 0.55s\n",
            "Epoch 5, 24% \t train_loss: 3.30 took: 0.41s\n",
            "Epoch 5, 36% \t train_loss: 3.34 took: 0.41s\n",
            "Epoch 5, 48% \t train_loss: 3.25 took: 0.41s\n",
            "Epoch 5, 60% \t train_loss: 3.20 took: 0.41s\n",
            "Epoch 5, 72% \t train_loss: 3.01 took: 0.41s\n",
            "Epoch 5, 84% \t train_loss: 3.12 took: 0.41s\n",
            "Epoch 5, 96% \t train_loss: 3.06 took: 0.41s\n",
            "Validation loss = 2.64\n",
            "Epoch 6, 12% \t train_loss: 3.27 took: 0.55s\n",
            "Epoch 6, 24% \t train_loss: 3.27 took: 0.42s\n",
            "Epoch 6, 36% \t train_loss: 3.30 took: 0.41s\n",
            "Epoch 6, 48% \t train_loss: 3.03 took: 0.41s\n",
            "Epoch 6, 60% \t train_loss: 3.23 took: 0.43s\n",
            "Epoch 6, 72% \t train_loss: 3.06 took: 0.42s\n",
            "Epoch 6, 84% \t train_loss: 3.04 took: 0.42s\n",
            "Epoch 6, 96% \t train_loss: 3.02 took: 0.40s\n",
            "Validation loss = 2.64\n",
            "Epoch 7, 12% \t train_loss: 2.97 took: 0.55s\n",
            "Epoch 7, 24% \t train_loss: 3.11 took: 0.42s\n",
            "Epoch 7, 36% \t train_loss: 3.18 took: 0.42s\n",
            "Epoch 7, 48% \t train_loss: 3.22 took: 0.41s\n",
            "Epoch 7, 60% \t train_loss: 3.23 took: 0.42s\n",
            "Epoch 7, 72% \t train_loss: 3.08 took: 0.41s\n",
            "Epoch 7, 84% \t train_loss: 2.95 took: 0.41s\n",
            "Epoch 7, 96% \t train_loss: 3.03 took: 0.42s\n",
            "Validation loss = 2.50\n",
            "Epoch 8, 12% \t train_loss: 2.98 took: 0.54s\n",
            "Epoch 8, 24% \t train_loss: 2.93 took: 0.41s\n",
            "Epoch 8, 36% \t train_loss: 3.07 took: 0.42s\n",
            "Epoch 8, 48% \t train_loss: 2.98 took: 0.41s\n",
            "Epoch 8, 60% \t train_loss: 2.77 took: 0.41s\n",
            "Epoch 8, 72% \t train_loss: 2.83 took: 0.43s\n",
            "Epoch 8, 84% \t train_loss: 2.96 took: 0.41s\n",
            "Epoch 8, 96% \t train_loss: 2.92 took: 0.42s\n",
            "Validation loss = 2.53\n",
            "Epoch 9, 12% \t train_loss: 3.05 took: 0.55s\n",
            "Epoch 9, 24% \t train_loss: 2.89 took: 0.43s\n",
            "Epoch 9, 36% \t train_loss: 2.95 took: 0.41s\n",
            "Epoch 9, 48% \t train_loss: 2.91 took: 0.42s\n",
            "Epoch 9, 60% \t train_loss: 2.92 took: 0.41s\n",
            "Epoch 9, 72% \t train_loss: 2.98 took: 0.41s\n",
            "Epoch 9, 84% \t train_loss: 2.91 took: 0.41s\n",
            "Epoch 9, 96% \t train_loss: 3.10 took: 0.41s\n",
            "Validation loss = 2.56\n",
            "Epoch 10, 12% \t train_loss: 2.95 took: 0.54s\n",
            "Epoch 10, 24% \t train_loss: 2.94 took: 0.41s\n",
            "Epoch 10, 36% \t train_loss: 3.08 took: 0.41s\n",
            "Epoch 10, 48% \t train_loss: 2.89 took: 0.41s\n",
            "Epoch 10, 60% \t train_loss: 2.97 took: 0.42s\n",
            "Epoch 10, 72% \t train_loss: 2.93 took: 0.40s\n",
            "Epoch 10, 84% \t train_loss: 2.86 took: 0.41s\n",
            "Epoch 10, 96% \t train_loss: 2.92 took: 0.43s\n",
            "Validation loss = 2.45\n",
            "Training finished, took 37.60s\n",
            "Testing Loss for model 1552913650.1968865 : 2.4387755155563355\n",
            "===== HYPERPARAMETERS =====\n",
            "batch_size= 10\n",
            "epochs= 10\n",
            "learning_rate= 0.01\n",
            "==============================\n",
            "Epoch 1, 12% \t train_loss: 15.60 took: 0.58s\n",
            "Epoch 1, 24% \t train_loss: 7.76 took: 0.43s\n",
            "Epoch 1, 36% \t train_loss: 4.28 took: 0.42s\n",
            "Epoch 1, 48% \t train_loss: 4.44 took: 0.43s\n",
            "Epoch 1, 60% \t train_loss: 5.13 took: 0.42s\n",
            "Epoch 1, 72% \t train_loss: 4.33 took: 0.41s\n",
            "Epoch 1, 84% \t train_loss: 4.45 took: 0.41s\n",
            "Epoch 1, 96% \t train_loss: 4.19 took: 0.42s\n",
            "Validation loss = 3.77\n",
            "Epoch 2, 12% \t train_loss: 4.44 took: 0.56s\n",
            "Epoch 2, 24% \t train_loss: 4.16 took: 0.41s\n",
            "Epoch 2, 36% \t train_loss: 3.49 took: 0.41s\n",
            "Epoch 2, 48% \t train_loss: 4.46 took: 0.41s\n",
            "Epoch 2, 60% \t train_loss: 4.13 took: 0.41s\n",
            "Epoch 2, 72% \t train_loss: 5.14 took: 0.42s\n",
            "Epoch 2, 84% \t train_loss: 4.93 took: 0.42s\n",
            "Epoch 2, 96% \t train_loss: 4.66 took: 0.42s\n",
            "Validation loss = 3.31\n",
            "Epoch 3, 12% \t train_loss: 4.19 took: 0.56s\n",
            "Epoch 3, 24% \t train_loss: 4.28 took: 0.42s\n",
            "Epoch 3, 36% \t train_loss: 4.50 took: 0.42s\n",
            "Epoch 3, 48% \t train_loss: 4.12 took: 0.42s\n",
            "Epoch 3, 60% \t train_loss: 4.05 took: 0.42s\n",
            "Epoch 3, 72% \t train_loss: 3.86 took: 0.42s\n",
            "Epoch 3, 84% \t train_loss: 3.94 took: 0.41s\n",
            "Epoch 3, 96% \t train_loss: 3.85 took: 0.41s\n",
            "Validation loss = 3.35\n",
            "Epoch 4, 12% \t train_loss: 4.66 took: 0.56s\n",
            "Epoch 4, 24% \t train_loss: 3.79 took: 0.42s\n",
            "Epoch 4, 36% \t train_loss: 3.73 took: 0.41s\n",
            "Epoch 4, 48% \t train_loss: 3.65 took: 0.41s\n",
            "Epoch 4, 60% \t train_loss: 3.63 took: 0.43s\n",
            "Epoch 4, 72% \t train_loss: 3.71 took: 0.41s\n",
            "Epoch 4, 84% \t train_loss: 3.59 took: 0.41s\n",
            "Epoch 4, 96% \t train_loss: 3.57 took: 0.41s\n",
            "Validation loss = 2.92\n",
            "Epoch 5, 12% \t train_loss: 3.48 took: 0.56s\n",
            "Epoch 5, 24% \t train_loss: 3.51 took: 0.42s\n",
            "Epoch 5, 36% \t train_loss: 3.45 took: 0.41s\n",
            "Epoch 5, 48% \t train_loss: 3.73 took: 0.42s\n",
            "Epoch 5, 60% \t train_loss: 3.84 took: 0.42s\n",
            "Epoch 5, 72% \t train_loss: 3.34 took: 0.42s\n",
            "Epoch 5, 84% \t train_loss: 3.32 took: 0.41s\n",
            "Epoch 5, 96% \t train_loss: 3.32 took: 0.41s\n",
            "Validation loss = 2.75\n",
            "Epoch 6, 12% \t train_loss: 3.27 took: 0.55s\n",
            "Epoch 6, 24% \t train_loss: 3.26 took: 0.42s\n",
            "Epoch 6, 36% \t train_loss: 3.26 took: 0.41s\n",
            "Epoch 6, 48% \t train_loss: 3.32 took: 0.42s\n",
            "Epoch 6, 60% \t train_loss: 3.21 took: 0.42s\n",
            "Epoch 6, 72% \t train_loss: 3.20 took: 0.41s\n",
            "Epoch 6, 84% \t train_loss: 3.15 took: 0.42s\n",
            "Epoch 6, 96% \t train_loss: 3.14 took: 0.41s\n",
            "Validation loss = 2.62\n",
            "Epoch 7, 12% \t train_loss: 3.12 took: 0.56s\n",
            "Epoch 7, 24% \t train_loss: 3.22 took: 0.42s\n",
            "Epoch 7, 36% \t train_loss: 3.11 took: 0.42s\n",
            "Epoch 7, 48% \t train_loss: 3.09 took: 0.42s\n",
            "Epoch 7, 60% \t train_loss: 3.08 took: 0.42s\n",
            "Epoch 7, 72% \t train_loss: 3.09 took: 0.42s\n",
            "Epoch 7, 84% \t train_loss: 3.05 took: 0.42s\n",
            "Epoch 7, 96% \t train_loss: 3.04 took: 0.42s\n",
            "Validation loss = 2.56\n",
            "Epoch 8, 12% \t train_loss: 3.02 took: 0.56s\n",
            "Epoch 8, 24% \t train_loss: 3.06 took: 0.42s\n",
            "Epoch 8, 36% \t train_loss: 3.02 took: 0.42s\n",
            "Epoch 8, 48% \t train_loss: 3.03 took: 0.42s\n",
            "Epoch 8, 60% \t train_loss: 3.26 took: 0.42s\n",
            "Epoch 8, 72% \t train_loss: 3.02 took: 0.42s\n",
            "Epoch 8, 84% \t train_loss: 3.04 took: 0.41s\n",
            "Epoch 8, 96% \t train_loss: 2.97 took: 0.41s\n",
            "Validation loss = 2.49\n",
            "Epoch 9, 12% \t train_loss: 3.06 took: 0.55s\n",
            "Epoch 9, 24% \t train_loss: 2.99 took: 0.42s\n",
            "Epoch 9, 36% \t train_loss: 2.95 took: 0.42s\n",
            "Epoch 9, 48% \t train_loss: 2.97 took: 0.42s\n",
            "Epoch 9, 60% \t train_loss: 2.95 took: 0.42s\n",
            "Epoch 9, 72% \t train_loss: 2.96 took: 0.41s\n",
            "Epoch 9, 84% \t train_loss: 2.94 took: 0.42s\n",
            "Epoch 9, 96% \t train_loss: 2.90 took: 0.42s\n",
            "Validation loss = 2.57\n",
            "Epoch 10, 12% \t train_loss: 3.82 took: 0.57s\n",
            "Epoch 10, 24% \t train_loss: 2.90 took: 0.42s\n",
            "Epoch 10, 36% \t train_loss: 2.94 took: 0.42s\n",
            "Epoch 10, 48% \t train_loss: 2.95 took: 0.42s\n",
            "Epoch 10, 60% \t train_loss: 2.91 took: 0.42s\n",
            "Epoch 10, 72% \t train_loss: 2.94 took: 0.42s\n",
            "Epoch 10, 84% \t train_loss: 2.93 took: 0.42s\n",
            "Epoch 10, 96% \t train_loss: 2.96 took: 0.43s\n",
            "Validation loss = 2.42\n",
            "Training finished, took 37.70s\n",
            "Testing Loss for model 1552913650.283256 : 2.396215081214905\n",
            "===== HYPERPARAMETERS =====\n",
            "batch_size= 10\n",
            "epochs= 10\n",
            "learning_rate= 0.01\n",
            "==============================\n",
            "Epoch 1, 12% \t train_loss: 69.14 took: 4.33s\n",
            "Epoch 1, 24% \t train_loss: 37.74 took: 3.78s\n",
            "Epoch 1, 36% \t train_loss: 6.56 took: 3.61s\n",
            "Epoch 1, 48% \t train_loss: 5.47 took: 3.64s\n",
            "Epoch 1, 60% \t train_loss: 3.95 took: 3.63s\n",
            "Epoch 1, 72% \t train_loss: 3.38 took: 3.62s\n",
            "Epoch 1, 84% \t train_loss: 3.62 took: 3.62s\n",
            "Epoch 1, 96% \t train_loss: 3.38 took: 3.61s\n",
            "Validation loss = 2.64\n",
            "Epoch 2, 12% \t train_loss: 3.44 took: 4.37s\n",
            "Epoch 2, 24% \t train_loss: 3.31 took: 3.63s\n",
            "Epoch 2, 36% \t train_loss: 3.05 took: 3.64s\n",
            "Epoch 2, 48% \t train_loss: 3.35 took: 3.63s\n",
            "Epoch 2, 60% \t train_loss: 3.12 took: 3.65s\n",
            "Epoch 2, 72% \t train_loss: 3.25 took: 3.63s\n",
            "Epoch 2, 84% \t train_loss: 3.31 took: 3.64s\n",
            "Epoch 2, 96% \t train_loss: 2.95 took: 3.63s\n",
            "Validation loss = 2.57\n",
            "Epoch 3, 12% \t train_loss: 2.95 took: 4.43s\n",
            "Epoch 3, 24% \t train_loss: 3.35 took: 3.67s\n",
            "Epoch 3, 36% \t train_loss: 3.07 took: 3.64s\n",
            "Epoch 3, 48% \t train_loss: 3.12 took: 3.67s\n",
            "Epoch 3, 60% \t train_loss: 2.99 took: 3.60s\n",
            "Epoch 3, 72% \t train_loss: 3.03 took: 3.55s\n",
            "Epoch 3, 84% \t train_loss: 3.28 took: 3.56s\n",
            "Epoch 3, 96% \t train_loss: 3.02 took: 3.63s\n",
            "Validation loss = 2.68\n",
            "Epoch 4, 12% \t train_loss: 3.12 took: 4.37s\n",
            "Epoch 4, 24% \t train_loss: 3.01 took: 3.63s\n",
            "Epoch 4, 36% \t train_loss: 3.09 took: 3.61s\n",
            "Epoch 4, 48% \t train_loss: 3.23 took: 3.61s\n",
            "Epoch 4, 60% \t train_loss: 2.95 took: 3.60s\n",
            "Epoch 4, 72% \t train_loss: 3.17 took: 3.62s\n",
            "Epoch 4, 84% \t train_loss: 3.12 took: 3.61s\n",
            "Epoch 4, 96% \t train_loss: 3.03 took: 3.60s\n",
            "Validation loss = 2.63\n",
            "Epoch 5, 12% \t train_loss: 2.78 took: 4.37s\n",
            "Epoch 5, 24% \t train_loss: 3.19 took: 3.62s\n",
            "Epoch 5, 36% \t train_loss: 3.05 took: 3.65s\n",
            "Epoch 5, 48% \t train_loss: 3.07 took: 3.62s\n",
            "Epoch 5, 60% \t train_loss: 2.86 took: 3.62s\n",
            "Epoch 5, 72% \t train_loss: 3.06 took: 3.62s\n",
            "Epoch 5, 84% \t train_loss: 3.22 took: 3.64s\n",
            "Epoch 5, 96% \t train_loss: 2.91 took: 3.60s\n",
            "Validation loss = 2.69\n",
            "Epoch 6, 12% \t train_loss: 3.01 took: 4.35s\n",
            "Epoch 6, 24% \t train_loss: 3.16 took: 3.61s\n",
            "Epoch 6, 36% \t train_loss: 2.94 took: 3.60s\n",
            "Epoch 6, 48% \t train_loss: 2.87 took: 3.64s\n",
            "Epoch 6, 60% \t train_loss: 2.86 took: 3.62s\n",
            "Epoch 6, 72% \t train_loss: 3.17 took: 3.62s\n",
            "Epoch 6, 84% \t train_loss: 3.01 took: 3.60s\n",
            "Epoch 6, 96% \t train_loss: 3.09 took: 3.62s\n",
            "Validation loss = 2.45\n",
            "Epoch 7, 12% \t train_loss: 3.12 took: 4.36s\n",
            "Epoch 7, 24% \t train_loss: 2.93 took: 3.60s\n",
            "Epoch 7, 36% \t train_loss: 2.96 took: 3.62s\n",
            "Epoch 7, 48% \t train_loss: 3.13 took: 3.60s\n",
            "Epoch 7, 60% \t train_loss: 2.94 took: 3.60s\n",
            "Epoch 7, 72% \t train_loss: 3.00 took: 3.61s\n",
            "Epoch 7, 84% \t train_loss: 3.21 took: 3.62s\n",
            "Epoch 7, 96% \t train_loss: 2.95 took: 3.61s\n",
            "Validation loss = 2.45\n",
            "Epoch 8, 12% \t train_loss: 2.93 took: 4.36s\n",
            "Epoch 8, 24% \t train_loss: 2.91 took: 3.59s\n",
            "Epoch 8, 36% \t train_loss: 3.08 took: 3.60s\n",
            "Epoch 8, 48% \t train_loss: 3.03 took: 3.60s\n",
            "Epoch 8, 60% \t train_loss: 3.05 took: 3.60s\n",
            "Epoch 8, 72% \t train_loss: 3.23 took: 3.60s\n",
            "Epoch 8, 84% \t train_loss: 3.15 took: 3.60s\n",
            "Epoch 8, 96% \t train_loss: 3.04 took: 3.60s\n",
            "Validation loss = 2.52\n",
            "Epoch 9, 12% \t train_loss: 3.13 took: 4.31s\n",
            "Epoch 9, 24% \t train_loss: 2.90 took: 3.62s\n",
            "Epoch 9, 36% \t train_loss: 3.06 took: 3.58s\n",
            "Epoch 9, 48% \t train_loss: 2.94 took: 3.59s\n",
            "Epoch 9, 60% \t train_loss: 2.86 took: 3.62s\n",
            "Epoch 9, 72% \t train_loss: 3.07 took: 3.61s\n",
            "Epoch 9, 84% \t train_loss: 3.10 took: 3.60s\n",
            "Epoch 9, 96% \t train_loss: 2.97 took: 3.59s\n",
            "Validation loss = 2.63\n",
            "Epoch 10, 12% \t train_loss: 3.12 took: 4.32s\n",
            "Epoch 10, 24% \t train_loss: 3.02 took: 3.52s\n",
            "Epoch 10, 36% \t train_loss: 2.86 took: 3.59s\n",
            "Epoch 10, 48% \t train_loss: 2.96 took: 3.60s\n",
            "Epoch 10, 60% \t train_loss: 3.15 took: 3.61s\n",
            "Epoch 10, 72% \t train_loss: 2.93 took: 3.59s\n",
            "Epoch 10, 84% \t train_loss: 3.11 took: 3.61s\n",
            "Epoch 10, 96% \t train_loss: 2.97 took: 3.59s\n",
            "Validation loss = 2.71\n",
            "Training finished, took 312.53s\n",
            "Testing Loss for model 1552913650.3433163 : 2.5285980701446533\n",
            "===== HYPERPARAMETERS =====\n",
            "batch_size= 10\n",
            "epochs= 10\n",
            "learning_rate= 0.01\n",
            "==============================\n",
            "Epoch 1, 12% \t train_loss: 10.00 took: 0.59s\n",
            "Epoch 1, 24% \t train_loss: 4.46 took: 0.44s\n",
            "Epoch 1, 36% \t train_loss: 4.11 took: 0.44s\n",
            "Epoch 1, 48% \t train_loss: 3.76 took: 0.44s\n",
            "Epoch 1, 60% \t train_loss: 3.90 took: 0.43s\n",
            "Epoch 1, 72% \t train_loss: 3.24 took: 0.44s\n",
            "Epoch 1, 84% \t train_loss: 3.58 took: 0.44s\n",
            "Epoch 1, 96% \t train_loss: 3.16 took: 0.44s\n",
            "Validation loss = 2.50\n",
            "Epoch 2, 12% \t train_loss: 3.13 took: 0.58s\n",
            "Epoch 2, 24% \t train_loss: 3.29 took: 0.44s\n",
            "Epoch 2, 36% \t train_loss: 3.10 took: 0.45s\n",
            "Epoch 2, 48% \t train_loss: 3.25 took: 0.44s\n",
            "Epoch 2, 60% \t train_loss: 2.92 took: 0.43s\n",
            "Epoch 2, 72% \t train_loss: 3.01 took: 0.43s\n",
            "Epoch 2, 84% \t train_loss: 2.96 took: 0.43s\n",
            "Epoch 2, 96% \t train_loss: 2.84 took: 0.43s\n",
            "Validation loss = 2.35\n",
            "Epoch 3, 12% \t train_loss: 2.92 took: 0.58s\n",
            "Epoch 3, 24% \t train_loss: 2.85 took: 0.44s\n",
            "Epoch 3, 36% \t train_loss: 2.79 took: 0.44s\n",
            "Epoch 3, 48% \t train_loss: 2.83 took: 0.43s\n",
            "Epoch 3, 60% \t train_loss: 2.86 took: 0.44s\n",
            "Epoch 3, 72% \t train_loss: 2.91 took: 0.44s\n",
            "Epoch 3, 84% \t train_loss: 2.87 took: 0.44s\n",
            "Epoch 3, 96% \t train_loss: 2.86 took: 0.43s\n",
            "Validation loss = 2.40\n",
            "Epoch 4, 12% \t train_loss: 2.83 took: 0.58s\n",
            "Epoch 4, 24% \t train_loss: 2.91 took: 0.44s\n",
            "Epoch 4, 36% \t train_loss: 2.93 took: 0.44s\n",
            "Epoch 4, 48% \t train_loss: 2.89 took: 0.43s\n",
            "Epoch 4, 60% \t train_loss: 2.79 took: 0.43s\n",
            "Epoch 4, 72% \t train_loss: 2.88 took: 0.43s\n",
            "Epoch 4, 84% \t train_loss: 2.81 took: 0.43s\n",
            "Epoch 4, 96% \t train_loss: 2.80 took: 0.44s\n",
            "Validation loss = 2.28\n",
            "Epoch 5, 12% \t train_loss: 2.75 took: 0.59s\n",
            "Epoch 5, 24% \t train_loss: 2.81 took: 0.44s\n",
            "Epoch 5, 36% \t train_loss: 2.97 took: 0.44s\n",
            "Epoch 5, 48% \t train_loss: 2.77 took: 0.44s\n",
            "Epoch 5, 60% \t train_loss: 2.99 took: 0.43s\n",
            "Epoch 5, 72% \t train_loss: 2.87 took: 0.44s\n",
            "Epoch 5, 84% \t train_loss: 2.90 took: 0.44s\n",
            "Epoch 5, 96% \t train_loss: 2.83 took: 0.43s\n",
            "Validation loss = 2.37\n",
            "Epoch 6, 12% \t train_loss: 2.75 took: 0.59s\n",
            "Epoch 6, 24% \t train_loss: 2.84 took: 0.44s\n",
            "Epoch 6, 36% \t train_loss: 2.74 took: 0.43s\n",
            "Epoch 6, 48% \t train_loss: 2.82 took: 0.43s\n",
            "Epoch 6, 60% \t train_loss: 2.88 took: 0.43s\n",
            "Epoch 6, 72% \t train_loss: 2.92 took: 0.44s\n",
            "Epoch 6, 84% \t train_loss: 2.96 took: 0.44s\n",
            "Epoch 6, 96% \t train_loss: 2.79 took: 0.44s\n",
            "Validation loss = 2.47\n",
            "Epoch 7, 12% \t train_loss: 2.88 took: 0.59s\n",
            "Epoch 7, 24% \t train_loss: 2.86 took: 0.44s\n",
            "Epoch 7, 36% \t train_loss: 2.92 took: 0.43s\n",
            "Epoch 7, 48% \t train_loss: 2.83 took: 0.43s\n",
            "Epoch 7, 60% \t train_loss: 2.83 took: 0.43s\n",
            "Epoch 7, 72% \t train_loss: 2.80 took: 0.44s\n",
            "Epoch 7, 84% \t train_loss: 2.83 took: 0.44s\n",
            "Epoch 7, 96% \t train_loss: 2.85 took: 0.44s\n",
            "Validation loss = 2.31\n",
            "Epoch 8, 12% \t train_loss: 2.81 took: 0.59s\n",
            "Epoch 8, 24% \t train_loss: 2.85 took: 0.45s\n",
            "Epoch 8, 36% \t train_loss: 2.85 took: 0.44s\n",
            "Epoch 8, 48% \t train_loss: 2.85 took: 0.44s\n",
            "Epoch 8, 60% \t train_loss: 2.91 took: 0.45s\n",
            "Epoch 8, 72% \t train_loss: 2.83 took: 0.43s\n",
            "Epoch 8, 84% \t train_loss: 2.91 took: 0.43s\n",
            "Epoch 8, 96% \t train_loss: 3.09 took: 0.44s\n",
            "Validation loss = 2.91\n",
            "Epoch 9, 12% \t train_loss: 3.11 took: 0.58s\n",
            "Epoch 9, 24% \t train_loss: 3.20 took: 0.44s\n",
            "Epoch 9, 36% \t train_loss: 3.12 took: 0.43s\n",
            "Epoch 9, 48% \t train_loss: 3.31 took: 0.44s\n",
            "Epoch 9, 60% \t train_loss: 3.13 took: 0.44s\n",
            "Epoch 9, 72% \t train_loss: 3.63 took: 0.44s\n",
            "Epoch 9, 84% \t train_loss: 3.26 took: 0.44s\n",
            "Epoch 9, 96% \t train_loss: 3.24 took: 0.44s\n",
            "Validation loss = 2.39\n",
            "Epoch 10, 12% \t train_loss: 2.96 took: 0.57s\n",
            "Epoch 10, 24% \t train_loss: 3.06 took: 0.44s\n",
            "Epoch 10, 36% \t train_loss: 2.90 took: 0.43s\n",
            "Epoch 10, 48% \t train_loss: 2.90 took: 0.43s\n",
            "Epoch 10, 60% \t train_loss: 3.28 took: 0.43s\n",
            "Epoch 10, 72% \t train_loss: 3.26 took: 0.43s\n",
            "Epoch 10, 84% \t train_loss: 3.09 took: 0.44s\n",
            "Epoch 10, 96% \t train_loss: 3.57 took: 0.44s\n",
            "Validation loss = 3.24\n",
            "Training finished, took 39.58s\n",
            "Testing Loss for model 1552913650.8148074 : 3.184508204460144\n",
            "===== HYPERPARAMETERS =====\n",
            "batch_size= 10\n",
            "epochs= 10\n",
            "learning_rate= 0.01\n",
            "==============================\n",
            "Epoch 1, 12% \t train_loss: 30.87 took: 6.68s\n",
            "Epoch 1, 24% \t train_loss: 10.38 took: 5.68s\n",
            "Epoch 1, 36% \t train_loss: 4.35 took: 5.67s\n",
            "Epoch 1, 48% \t train_loss: 4.16 took: 5.63s\n",
            "Epoch 1, 60% \t train_loss: 3.71 took: 5.65s\n",
            "Epoch 1, 72% \t train_loss: 3.53 took: 5.64s\n",
            "Epoch 1, 84% \t train_loss: 3.77 took: 5.65s\n",
            "Epoch 1, 96% \t train_loss: 3.51 took: 5.58s\n",
            "Validation loss = 2.69\n",
            "Epoch 2, 12% \t train_loss: 3.09 took: 6.67s\n",
            "Epoch 2, 24% \t train_loss: 3.53 took: 5.66s\n",
            "Epoch 2, 36% \t train_loss: 3.31 took: 5.62s\n",
            "Epoch 2, 48% \t train_loss: 3.71 took: 5.65s\n",
            "Epoch 2, 60% \t train_loss: 3.59 took: 5.66s\n",
            "Epoch 2, 72% \t train_loss: 3.42 took: 5.62s\n",
            "Epoch 2, 84% \t train_loss: 3.24 took: 5.63s\n",
            "Epoch 2, 96% \t train_loss: 3.85 took: 5.64s\n",
            "Validation loss = 2.96\n",
            "Epoch 3, 12% \t train_loss: 3.50 took: 6.59s\n",
            "Epoch 3, 24% \t train_loss: 3.27 took: 5.73s\n",
            "Epoch 3, 36% \t train_loss: 3.36 took: 5.65s\n",
            "Epoch 3, 48% \t train_loss: 3.53 took: 5.67s\n",
            "Epoch 3, 60% \t train_loss: 3.33 took: 5.64s\n",
            "Epoch 3, 72% \t train_loss: 3.56 took: 5.65s\n",
            "Epoch 3, 84% \t train_loss: 3.53 took: 5.66s\n",
            "Epoch 3, 96% \t train_loss: 3.34 took: 5.64s\n",
            "Validation loss = 2.62\n",
            "Epoch 4, 12% \t train_loss: 3.35 took: 6.63s\n",
            "Epoch 4, 24% \t train_loss: 3.42 took: 5.65s\n",
            "Epoch 4, 36% \t train_loss: 3.49 took: 5.63s\n",
            "Epoch 4, 48% \t train_loss: 3.51 took: 5.64s\n",
            "Epoch 4, 60% \t train_loss: 3.51 took: 5.65s\n",
            "Epoch 4, 72% \t train_loss: 3.34 took: 5.67s\n",
            "Epoch 4, 84% \t train_loss: 3.38 took: 5.63s\n",
            "Epoch 4, 96% \t train_loss: 3.04 took: 5.62s\n",
            "Validation loss = 2.98\n",
            "Epoch 5, 12% \t train_loss: 3.65 took: 6.64s\n",
            "Epoch 5, 24% \t train_loss: 3.57 took: 5.68s\n",
            "Epoch 5, 36% \t train_loss: 3.49 took: 5.61s\n",
            "Epoch 5, 48% \t train_loss: 3.56 took: 5.67s\n",
            "Epoch 5, 60% \t train_loss: 3.91 took: 5.65s\n",
            "Epoch 5, 72% \t train_loss: 3.32 took: 5.64s\n",
            "Epoch 5, 84% \t train_loss: 3.67 took: 5.65s\n",
            "Epoch 5, 96% \t train_loss: 3.33 took: 5.63s\n",
            "Validation loss = 3.22\n",
            "Epoch 6, 12% \t train_loss: 3.40 took: 6.67s\n",
            "Epoch 6, 24% \t train_loss: 3.73 took: 5.68s\n",
            "Epoch 6, 36% \t train_loss: 3.52 took: 5.70s\n",
            "Epoch 6, 48% \t train_loss: 3.55 took: 5.70s\n",
            "Epoch 6, 60% \t train_loss: 3.80 took: 5.70s\n",
            "Epoch 6, 72% \t train_loss: 3.47 took: 5.73s\n",
            "Epoch 6, 84% \t train_loss: 3.70 took: 5.66s\n",
            "Epoch 6, 96% \t train_loss: 3.29 took: 5.69s\n",
            "Validation loss = 2.89\n",
            "Epoch 7, 12% \t train_loss: 3.90 took: 6.70s\n",
            "Epoch 7, 24% \t train_loss: 3.45 took: 5.68s\n",
            "Epoch 7, 36% \t train_loss: 3.56 took: 5.67s\n",
            "Epoch 7, 48% \t train_loss: 3.90 took: 5.68s\n",
            "Epoch 7, 60% \t train_loss: 3.94 took: 5.66s\n",
            "Epoch 7, 72% \t train_loss: 3.82 took: 5.67s\n",
            "Epoch 7, 84% \t train_loss: 3.34 took: 5.65s\n",
            "Epoch 7, 96% \t train_loss: 3.69 took: 5.66s\n",
            "Validation loss = 3.19\n",
            "Epoch 8, 12% \t train_loss: 3.82 took: 6.63s\n",
            "Epoch 8, 24% \t train_loss: 3.52 took: 5.62s\n",
            "Epoch 8, 36% \t train_loss: 3.97 took: 5.59s\n",
            "Epoch 8, 48% \t train_loss: 3.92 took: 5.66s\n",
            "Epoch 8, 60% \t train_loss: 3.31 took: 5.66s\n",
            "Epoch 8, 72% \t train_loss: 3.71 took: 5.62s\n",
            "Epoch 8, 84% \t train_loss: 3.40 took: 5.62s\n",
            "Epoch 8, 96% \t train_loss: 3.78 took: 5.64s\n",
            "Validation loss = 3.02\n",
            "Epoch 9, 12% \t train_loss: 3.97 took: 6.69s\n",
            "Epoch 9, 24% \t train_loss: 3.77 took: 5.67s\n",
            "Epoch 9, 36% \t train_loss: 3.70 took: 5.67s\n",
            "Epoch 9, 48% \t train_loss: 3.89 took: 5.73s\n",
            "Epoch 9, 60% \t train_loss: 3.95 took: 5.72s\n",
            "Epoch 9, 72% \t train_loss: 3.51 took: 5.74s\n",
            "Epoch 9, 84% \t train_loss: 3.66 took: 5.71s\n",
            "Epoch 9, 96% \t train_loss: 3.29 took: 5.67s\n",
            "Validation loss = 3.07\n",
            "Epoch 10, 12% \t train_loss: 3.20 took: 6.63s\n",
            "Epoch 10, 24% \t train_loss: 3.62 took: 5.65s\n",
            "Epoch 10, 36% \t train_loss: 3.57 took: 5.65s\n",
            "Epoch 10, 48% \t train_loss: 3.78 took: 5.66s\n",
            "Epoch 10, 60% \t train_loss: 3.58 took: 5.65s\n",
            "Epoch 10, 72% \t train_loss: 3.79 took: 5.69s\n",
            "Epoch 10, 84% \t train_loss: 3.71 took: 5.68s\n",
            "Epoch 10, 96% \t train_loss: 3.82 took: 5.66s\n",
            "Validation loss = 3.09\n",
            "Training finished, took 486.54s\n",
            "Testing Loss for model 1552913650.8682811 : 2.728770446777344\n",
            "===== HYPERPARAMETERS =====\n",
            "batch_size= 10\n",
            "epochs= 10\n",
            "learning_rate= 0.01\n",
            "==============================\n",
            "Epoch 1, 12% \t train_loss: 30.28 took: 6.90s\n",
            "Epoch 1, 24% \t train_loss: 9.86 took: 5.69s\n",
            "Epoch 1, 36% \t train_loss: 4.18 took: 5.61s\n",
            "Epoch 1, 48% \t train_loss: 4.79 took: 5.66s\n",
            "Epoch 1, 60% \t train_loss: 4.56 took: 5.63s\n",
            "Epoch 1, 72% \t train_loss: 3.66 took: 5.60s\n",
            "Epoch 1, 84% \t train_loss: 3.97 took: 5.65s\n",
            "Epoch 1, 96% \t train_loss: 3.61 took: 5.64s\n",
            "Validation loss = 2.86\n",
            "Epoch 2, 12% \t train_loss: 3.34 took: 6.60s\n",
            "Epoch 2, 24% \t train_loss: 3.56 took: 5.59s\n",
            "Epoch 2, 36% \t train_loss: 3.64 took: 5.61s\n",
            "Epoch 2, 48% \t train_loss: 3.48 took: 5.61s\n",
            "Epoch 2, 60% \t train_loss: 3.34 took: 5.58s\n",
            "Epoch 2, 72% \t train_loss: 3.38 took: 5.59s\n",
            "Epoch 2, 84% \t train_loss: 3.41 took: 5.62s\n",
            "Epoch 2, 96% \t train_loss: 3.32 took: 5.59s\n",
            "Validation loss = 2.88\n",
            "Epoch 3, 12% \t train_loss: 3.47 took: 6.63s\n",
            "Epoch 3, 24% \t train_loss: 3.50 took: 5.62s\n",
            "Epoch 3, 36% \t train_loss: 3.63 took: 5.65s\n",
            "Epoch 3, 48% \t train_loss: 3.67 took: 5.62s\n",
            "Epoch 3, 60% \t train_loss: 3.49 took: 5.65s\n",
            "Epoch 3, 72% \t train_loss: 3.77 took: 5.66s\n",
            "Epoch 3, 84% \t train_loss: 3.51 took: 5.60s\n",
            "Epoch 3, 96% \t train_loss: 3.36 took: 5.62s\n",
            "Validation loss = 3.02\n",
            "Epoch 4, 12% \t train_loss: 3.52 took: 6.63s\n",
            "Epoch 4, 24% \t train_loss: 3.35 took: 5.63s\n",
            "Epoch 4, 36% \t train_loss: 3.60 took: 5.69s\n",
            "Epoch 4, 48% \t train_loss: 3.27 took: 5.61s\n",
            "Epoch 4, 60% \t train_loss: 3.56 took: 5.62s\n",
            "Epoch 4, 72% \t train_loss: 3.68 took: 5.57s\n",
            "Epoch 4, 84% \t train_loss: 3.35 took: 5.60s\n",
            "Epoch 4, 96% \t train_loss: 3.26 took: 5.62s\n",
            "Validation loss = 3.26\n",
            "Epoch 5, 12% \t train_loss: 3.48 took: 6.65s\n",
            "Epoch 5, 24% \t train_loss: 3.81 took: 5.66s\n",
            "Epoch 5, 36% \t train_loss: 3.42 took: 5.69s\n",
            "Epoch 5, 48% \t train_loss: 3.91 took: 5.63s\n",
            "Epoch 5, 60% \t train_loss: 3.44 took: 5.63s\n",
            "Epoch 5, 72% \t train_loss: 3.61 took: 5.67s\n",
            "Epoch 5, 84% \t train_loss: 3.48 took: 5.68s\n",
            "Epoch 5, 96% \t train_loss: 3.38 took: 5.70s\n",
            "Validation loss = 3.14\n",
            "Epoch 6, 12% \t train_loss: 3.70 took: 6.64s\n",
            "Epoch 6, 24% \t train_loss: 3.09 took: 5.63s\n",
            "Epoch 6, 36% \t train_loss: 3.18 took: 5.64s\n",
            "Epoch 6, 48% \t train_loss: 4.01 took: 5.61s\n",
            "Epoch 6, 60% \t train_loss: 3.48 took: 5.64s\n",
            "Epoch 6, 72% \t train_loss: 3.29 took: 5.61s\n",
            "Epoch 6, 84% \t train_loss: 3.70 took: 5.64s\n",
            "Epoch 6, 96% \t train_loss: 3.58 took: 5.61s\n",
            "Validation loss = 2.78\n",
            "Epoch 7, 12% \t train_loss: 3.18 took: 6.57s\n",
            "Epoch 7, 24% \t train_loss: 3.63 took: 5.65s\n",
            "Epoch 7, 36% \t train_loss: 3.83 took: 5.66s\n",
            "Epoch 7, 48% \t train_loss: 3.64 took: 5.60s\n",
            "Epoch 7, 60% \t train_loss: 3.74 took: 5.62s\n",
            "Epoch 7, 72% \t train_loss: 3.37 took: 5.61s\n",
            "Epoch 7, 84% \t train_loss: 3.82 took: 5.66s\n",
            "Epoch 7, 96% \t train_loss: 3.57 took: 5.62s\n",
            "Validation loss = 3.00\n",
            "Epoch 8, 12% \t train_loss: 3.81 took: 6.62s\n",
            "Epoch 8, 24% \t train_loss: 3.90 took: 5.64s\n",
            "Epoch 8, 36% \t train_loss: 3.35 took: 5.60s\n",
            "Epoch 8, 48% \t train_loss: 3.63 took: 5.64s\n",
            "Epoch 8, 60% \t train_loss: 4.22 took: 5.60s\n",
            "Epoch 8, 72% \t train_loss: 3.74 took: 5.62s\n",
            "Epoch 8, 84% \t train_loss: 3.81 took: 5.63s\n",
            "Epoch 8, 96% \t train_loss: 3.35 took: 5.61s\n",
            "Validation loss = 2.83\n",
            "Epoch 9, 12% \t train_loss: 3.62 took: 6.65s\n",
            "Epoch 9, 24% \t train_loss: 3.74 took: 5.60s\n",
            "Epoch 9, 36% \t train_loss: 3.38 took: 5.69s\n",
            "Epoch 9, 48% \t train_loss: 3.18 took: 5.66s\n",
            "Epoch 9, 60% \t train_loss: 4.38 took: 5.63s\n",
            "Epoch 9, 72% \t train_loss: 3.69 took: 5.62s\n",
            "Epoch 9, 84% \t train_loss: 3.46 took: 5.65s\n",
            "Epoch 9, 96% \t train_loss: 3.71 took: 5.62s\n",
            "Validation loss = 2.91\n",
            "Epoch 10, 12% \t train_loss: 3.80 took: 6.63s\n",
            "Epoch 10, 24% \t train_loss: 3.26 took: 5.64s\n",
            "Epoch 10, 36% \t train_loss: 3.92 took: 5.66s\n",
            "Epoch 10, 48% \t train_loss: 3.45 took: 5.63s\n",
            "Epoch 10, 60% \t train_loss: 3.86 took: 5.61s\n",
            "Epoch 10, 72% \t train_loss: 3.84 took: 5.62s\n",
            "Epoch 10, 84% \t train_loss: 3.62 took: 5.60s\n",
            "Epoch 10, 96% \t train_loss: 3.25 took: 5.62s\n",
            "Validation loss = 2.98\n",
            "Training finished, took 484.51s\n",
            "Testing Loss for model 1552913651.514498 : 3.063951849937439\n",
            "===== HYPERPARAMETERS =====\n",
            "batch_size= 10\n",
            "epochs= 10\n",
            "learning_rate= 0.01\n",
            "==============================\n",
            "Epoch 1, 12% \t train_loss: 56.94 took: 4.67s\n",
            "Epoch 1, 24% \t train_loss: 26.01 took: 3.73s\n",
            "Epoch 1, 36% \t train_loss: 6.36 took: 3.69s\n",
            "Epoch 1, 48% \t train_loss: 5.18 took: 3.68s\n",
            "Epoch 1, 60% \t train_loss: 3.74 took: 3.68s\n",
            "Epoch 1, 72% \t train_loss: 3.85 took: 3.69s\n",
            "Epoch 1, 84% \t train_loss: 3.48 took: 3.70s\n",
            "Epoch 1, 96% \t train_loss: 3.35 took: 3.69s\n",
            "Validation loss = 2.76\n",
            "Epoch 2, 12% \t train_loss: 3.47 took: 4.41s\n",
            "Epoch 2, 24% \t train_loss: 3.21 took: 3.68s\n",
            "Epoch 2, 36% \t train_loss: 3.15 took: 3.70s\n",
            "Epoch 2, 48% \t train_loss: 3.10 took: 3.70s\n",
            "Epoch 2, 60% \t train_loss: 3.22 took: 3.68s\n",
            "Epoch 2, 72% \t train_loss: 3.09 took: 3.66s\n",
            "Epoch 2, 84% \t train_loss: 2.95 took: 3.65s\n",
            "Epoch 2, 96% \t train_loss: 3.27 took: 3.68s\n",
            "Validation loss = 2.77\n",
            "Epoch 3, 12% \t train_loss: 3.02 took: 4.45s\n",
            "Epoch 3, 24% \t train_loss: 2.93 took: 3.70s\n",
            "Epoch 3, 36% \t train_loss: 3.21 took: 3.71s\n",
            "Epoch 3, 48% \t train_loss: 2.99 took: 3.71s\n",
            "Epoch 3, 60% \t train_loss: 3.35 took: 3.68s\n",
            "Epoch 3, 72% \t train_loss: 3.17 took: 3.70s\n",
            "Epoch 3, 84% \t train_loss: 3.09 took: 3.71s\n",
            "Epoch 3, 96% \t train_loss: 2.97 took: 3.72s\n",
            "Validation loss = 2.54\n",
            "Epoch 4, 12% \t train_loss: 3.07 took: 4.45s\n",
            "Epoch 4, 24% \t train_loss: 2.94 took: 3.67s\n",
            "Epoch 4, 36% \t train_loss: 2.89 took: 3.66s\n",
            "Epoch 4, 48% \t train_loss: 2.93 took: 3.65s\n",
            "Epoch 4, 60% \t train_loss: 2.82 took: 3.65s\n",
            "Epoch 4, 72% \t train_loss: 2.97 took: 3.66s\n",
            "Epoch 4, 84% \t train_loss: 2.74 took: 3.67s\n",
            "Epoch 4, 96% \t train_loss: 3.01 took: 3.68s\n",
            "Validation loss = 2.61\n",
            "Epoch 5, 12% \t train_loss: 2.86 took: 4.43s\n",
            "Epoch 5, 24% \t train_loss: 2.91 took: 3.68s\n",
            "Epoch 5, 36% \t train_loss: 2.99 took: 3.67s\n",
            "Epoch 5, 48% \t train_loss: 2.86 took: 3.70s\n",
            "Epoch 5, 60% \t train_loss: 3.13 took: 3.69s\n",
            "Epoch 5, 72% \t train_loss: 2.99 took: 3.68s\n",
            "Epoch 5, 84% \t train_loss: 3.07 took: 3.68s\n",
            "Epoch 5, 96% \t train_loss: 3.20 took: 3.69s\n",
            "Validation loss = 2.49\n",
            "Epoch 6, 12% \t train_loss: 3.13 took: 4.44s\n",
            "Epoch 6, 24% \t train_loss: 3.05 took: 3.69s\n",
            "Epoch 6, 36% \t train_loss: 2.89 took: 3.69s\n",
            "Epoch 6, 48% \t train_loss: 2.93 took: 3.69s\n",
            "Epoch 6, 60% \t train_loss: 2.86 took: 3.68s\n",
            "Epoch 6, 72% \t train_loss: 2.93 took: 3.71s\n",
            "Epoch 6, 84% \t train_loss: 2.93 took: 3.67s\n",
            "Epoch 6, 96% \t train_loss: 3.00 took: 3.67s\n",
            "Validation loss = 2.41\n",
            "Epoch 7, 12% \t train_loss: 2.99 took: 4.47s\n",
            "Epoch 7, 24% \t train_loss: 3.00 took: 3.73s\n",
            "Epoch 7, 36% \t train_loss: 3.01 took: 3.73s\n",
            "Epoch 7, 48% \t train_loss: 2.84 took: 3.73s\n",
            "Epoch 7, 60% \t train_loss: 2.99 took: 3.74s\n",
            "Epoch 7, 72% \t train_loss: 2.91 took: 3.73s\n",
            "Epoch 7, 84% \t train_loss: 2.98 took: 3.73s\n",
            "Epoch 7, 96% \t train_loss: 2.90 took: 3.73s\n",
            "Validation loss = 2.45\n",
            "Epoch 8, 12% \t train_loss: 2.82 took: 4.44s\n",
            "Epoch 8, 24% \t train_loss: 3.00 took: 3.70s\n",
            "Epoch 8, 36% \t train_loss: 2.78 took: 3.69s\n",
            "Epoch 8, 48% \t train_loss: 3.03 took: 3.69s\n",
            "Epoch 8, 60% \t train_loss: 2.99 took: 3.72s\n",
            "Epoch 8, 72% \t train_loss: 3.07 took: 3.69s\n",
            "Epoch 8, 84% \t train_loss: 3.03 took: 3.69s\n",
            "Epoch 8, 96% \t train_loss: 2.97 took: 3.70s\n",
            "Validation loss = 2.47\n",
            "Epoch 9, 12% \t train_loss: 2.94 took: 4.44s\n",
            "Epoch 9, 24% \t train_loss: 2.90 took: 3.69s\n",
            "Epoch 9, 36% \t train_loss: 3.03 took: 3.68s\n",
            "Epoch 9, 48% \t train_loss: 2.88 took: 3.67s\n",
            "Epoch 9, 60% \t train_loss: 2.97 took: 3.68s\n",
            "Epoch 9, 72% \t train_loss: 2.97 took: 3.71s\n",
            "Epoch 9, 84% \t train_loss: 2.99 took: 3.67s\n",
            "Epoch 9, 96% \t train_loss: 2.84 took: 3.70s\n",
            "Validation loss = 2.52\n",
            "Epoch 10, 12% \t train_loss: 2.83 took: 4.43s\n",
            "Epoch 10, 24% \t train_loss: 2.98 took: 3.67s\n",
            "Epoch 10, 36% \t train_loss: 2.92 took: 3.67s\n",
            "Epoch 10, 48% \t train_loss: 2.97 took: 3.68s\n",
            "Epoch 10, 60% \t train_loss: 2.92 took: 3.64s\n",
            "Epoch 10, 72% \t train_loss: 2.99 took: 3.68s\n",
            "Epoch 10, 84% \t train_loss: 2.84 took: 3.64s\n",
            "Epoch 10, 96% \t train_loss: 2.94 took: 3.63s\n",
            "Validation loss = 2.59\n",
            "Training finished, took 319.37s\n",
            "Testing Loss for model 1552913652.1413217 : 2.5782875061035155\n",
            "===== HYPERPARAMETERS =====\n",
            "batch_size= 10\n",
            "epochs= 10\n",
            "learning_rate= 0.01\n",
            "==============================\n",
            "Epoch 1, 12% \t train_loss: 100.48 took: 0.60s\n",
            "Epoch 1, 24% \t train_loss: 180.56 took: 0.43s\n",
            "Epoch 1, 36% \t train_loss: 272.00 took: 0.42s\n",
            "Epoch 1, 48% \t train_loss: 486.95 took: 0.42s\n",
            "Epoch 1, 60% \t train_loss: 510.91 took: 0.42s\n",
            "Epoch 1, 72% \t train_loss: 448.61 took: 0.41s\n",
            "Epoch 1, 84% \t train_loss: 695.85 took: 0.41s\n",
            "Epoch 1, 96% \t train_loss: 501.43 took: 0.41s\n",
            "Validation loss = 454.36\n",
            "Epoch 2, 12% \t train_loss: 798.33 took: 0.58s\n",
            "Epoch 2, 24% \t train_loss: 679.16 took: 0.40s\n",
            "Epoch 2, 36% \t train_loss: 710.86 took: 0.41s\n",
            "Epoch 2, 48% \t train_loss: 703.12 took: 0.40s\n",
            "Epoch 2, 60% \t train_loss: 772.67 took: 0.41s\n",
            "Epoch 2, 72% \t train_loss: 773.10 took: 0.41s\n",
            "Epoch 2, 84% \t train_loss: 913.08 took: 0.40s\n",
            "Epoch 2, 96% \t train_loss: 710.53 took: 0.40s\n",
            "Validation loss = 1000.09\n",
            "Epoch 3, 12% \t train_loss: 1518.07 took: 0.57s\n",
            "Epoch 3, 24% \t train_loss: 707.54 took: 0.40s\n",
            "Epoch 3, 36% \t train_loss: 1525.71 took: 0.40s\n",
            "Epoch 3, 48% \t train_loss: 1579.48 took: 0.41s\n",
            "Epoch 3, 60% \t train_loss: 1350.07 took: 0.40s\n",
            "Epoch 3, 72% \t train_loss: 1727.72 took: 0.41s\n",
            "Epoch 3, 84% \t train_loss: 1576.50 took: 0.40s\n",
            "Epoch 3, 96% \t train_loss: 1902.79 took: 0.40s\n",
            "Validation loss = 1418.39\n",
            "Epoch 4, 12% \t train_loss: 1978.00 took: 0.56s\n",
            "Epoch 4, 24% \t train_loss: 2511.36 took: 0.40s\n",
            "Epoch 4, 36% \t train_loss: 2427.02 took: 0.40s\n",
            "Epoch 4, 48% \t train_loss: 2338.69 took: 0.40s\n",
            "Epoch 4, 60% \t train_loss: 2198.58 took: 0.40s\n",
            "Epoch 4, 72% \t train_loss: 2322.41 took: 0.40s\n",
            "Epoch 4, 84% \t train_loss: 2225.17 took: 0.40s\n",
            "Epoch 4, 96% \t train_loss: 2693.43 took: 0.39s\n",
            "Validation loss = 1931.59\n",
            "Epoch 5, 12% \t train_loss: 2717.13 took: 0.57s\n",
            "Epoch 5, 24% \t train_loss: 2405.43 took: 0.41s\n",
            "Epoch 5, 36% \t train_loss: 2548.35 took: 0.41s\n",
            "Epoch 5, 48% \t train_loss: 2163.47 took: 0.41s\n",
            "Epoch 5, 60% \t train_loss: 2814.05 took: 0.41s\n",
            "Epoch 5, 72% \t train_loss: 3558.79 took: 0.41s\n",
            "Epoch 5, 84% \t train_loss: 3317.74 took: 0.40s\n",
            "Epoch 5, 96% \t train_loss: 2764.68 took: 0.41s\n",
            "Validation loss = 2439.53\n",
            "Epoch 6, 12% \t train_loss: 3209.77 took: 0.57s\n",
            "Epoch 6, 24% \t train_loss: 3026.29 took: 0.40s\n",
            "Epoch 6, 36% \t train_loss: 2671.87 took: 0.40s\n",
            "Epoch 6, 48% \t train_loss: 3192.45 took: 0.40s\n",
            "Epoch 6, 60% \t train_loss: 3544.02 took: 0.39s\n",
            "Epoch 6, 72% \t train_loss: 4060.54 took: 0.40s\n",
            "Epoch 6, 84% \t train_loss: 3675.24 took: 0.40s\n",
            "Epoch 6, 96% \t train_loss: 3427.34 took: 0.39s\n",
            "Validation loss = 3253.00\n",
            "Epoch 7, 12% \t train_loss: 3401.29 took: 0.56s\n",
            "Epoch 7, 24% \t train_loss: 3246.36 took: 0.41s\n",
            "Epoch 7, 36% \t train_loss: 3224.58 took: 0.41s\n",
            "Epoch 7, 48% \t train_loss: 3844.03 took: 0.40s\n",
            "Epoch 7, 60% \t train_loss: 2972.15 took: 0.40s\n",
            "Epoch 7, 72% \t train_loss: 3932.86 took: 0.40s\n",
            "Epoch 7, 84% \t train_loss: 3554.26 took: 0.41s\n",
            "Epoch 7, 96% \t train_loss: 4141.76 took: 0.40s\n",
            "Validation loss = 3086.55\n",
            "Epoch 8, 12% \t train_loss: 3773.23 took: 0.56s\n",
            "Epoch 8, 24% \t train_loss: 3807.64 took: 0.40s\n",
            "Epoch 8, 36% \t train_loss: 3939.32 took: 0.41s\n",
            "Epoch 8, 48% \t train_loss: 4230.42 took: 0.40s\n",
            "Epoch 8, 60% \t train_loss: 4163.07 took: 0.40s\n",
            "Epoch 8, 72% \t train_loss: 4905.55 took: 0.40s\n",
            "Epoch 8, 84% \t train_loss: 5239.05 took: 0.40s\n",
            "Epoch 8, 96% \t train_loss: 4806.32 took: 0.40s\n",
            "Validation loss = 3908.95\n",
            "Epoch 9, 12% \t train_loss: 4579.61 took: 0.57s\n",
            "Epoch 9, 24% \t train_loss: 3808.31 took: 0.40s\n",
            "Epoch 9, 36% \t train_loss: 5952.42 took: 0.40s\n",
            "Epoch 9, 48% \t train_loss: 4404.51 took: 0.41s\n",
            "Epoch 9, 60% \t train_loss: 3769.30 took: 0.40s\n",
            "Epoch 9, 72% \t train_loss: 4386.54 took: 0.41s\n",
            "Epoch 9, 84% \t train_loss: 4434.24 took: 0.39s\n",
            "Epoch 9, 96% \t train_loss: 4362.63 took: 0.40s\n",
            "Validation loss = 3011.98\n",
            "Epoch 10, 12% \t train_loss: 4639.84 took: 0.55s\n",
            "Epoch 10, 24% \t train_loss: 3718.05 took: 0.40s\n",
            "Epoch 10, 36% \t train_loss: 4136.36 took: 0.39s\n",
            "Epoch 10, 48% \t train_loss: 3945.02 took: 0.39s\n",
            "Epoch 10, 60% \t train_loss: 4182.63 took: 0.40s\n",
            "Epoch 10, 72% \t train_loss: 3862.36 took: 0.39s\n",
            "Epoch 10, 84% \t train_loss: 4352.34 took: 0.39s\n",
            "Epoch 10, 96% \t train_loss: 3371.33 took: 0.39s\n",
            "Validation loss = 4041.84\n",
            "Training finished, took 37.39s\n",
            "Testing Loss for model 1552913652.682875 : 3573.5928466796877\n",
            "[4, 2] [3, 2]\n",
            "10 8\n",
            "70 4\n",
            "ModuleList(\n",
            "  (0): Linear(in_features=7840, out_features=640, bias=True)\n",
            "  (1): Dropout(p=0.4)\n",
            "  (2): Conv2d(10, 70, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (3): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (4): Dropout(p=0.5)\n",
            "  (5): Linear(in_features=1120, out_features=700, bias=True)\n",
            ")\n",
            "10 8\n",
            "70 4\n",
            "ModuleList(\n",
            "  (0): Linear(in_features=7840, out_features=640, bias=True)\n",
            "  (1): Conv2d(10, 70, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (3): Dropout(p=0.5)\n",
            "  (4): Linear(in_features=1120, out_features=700, bias=True)\n",
            ")\n",
            "[3, 3] [1, 1]\n",
            "10 8\n",
            "10 8\n",
            "ModuleList(\n",
            "  (0): Linear(in_features=7840, out_features=640, bias=True)\n",
            "  (1): Linear(in_features=640, out_features=640, bias=True)\n",
            "  (2): Linear(in_features=640, out_features=100, bias=True)\n",
            ")\n",
            "60 14\n",
            "360 7\n",
            "ModuleList(\n",
            "  (0): Conv2d(10, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (2): Conv2d(60, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (3): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (4): Linear(in_features=17640, out_features=3600, bias=True)\n",
            ")\n",
            "[2, 4] [2, 4]\n",
            "70 14\n",
            "70 8\n",
            "ModuleList(\n",
            "  (0): Conv2d(10, 70, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (2): Dropout(p=0.5)\n",
            "  (3): Linear(in_features=13720, out_features=4480, bias=True)\n",
            "  (4): Dropout(p=0.4)\n",
            "  (5): Linear(in_features=4480, out_features=700, bias=True)\n",
            ")\n",
            "70 14\n",
            "70 8\n",
            "ModuleList(\n",
            "  (0): Conv2d(10, 70, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (2): Dropout(p=0.5)\n",
            "  (3): Linear(in_features=13720, out_features=4480, bias=True)\n",
            "  (4): Dropout(p=0.4)\n",
            "  (5): Linear(in_features=4480, out_features=700, bias=True)\n",
            ")\n",
            "[3, 3] [1, 4]\n",
            "10 8\n",
            "10 8\n",
            "ModuleList(\n",
            "  (0): Linear(in_features=7840, out_features=640, bias=True)\n",
            "  (1): Linear(in_features=640, out_features=640, bias=True)\n",
            "  (2): Linear(in_features=640, out_features=100, bias=True)\n",
            ")\n",
            "60 14\n",
            "60 8\n",
            "ModuleList(\n",
            "  (0): Conv2d(10, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (2): Linear(in_features=11760, out_features=3840, bias=True)\n",
            "  (3): Dropout(p=0.4)\n",
            "  (4): Linear(in_features=3840, out_features=600, bias=True)\n",
            ")\n",
            "===== HYPERPARAMETERS =====\n",
            "batch_size= 10\n",
            "epochs= 10\n",
            "learning_rate= 0.01\n",
            "==============================\n",
            "Epoch 1, 12% \t train_loss: 29.97 took: 0.68s\n",
            "Epoch 1, 24% \t train_loss: 5.16 took: 0.50s\n",
            "Epoch 1, 36% \t train_loss: 4.43 took: 0.50s\n",
            "Epoch 1, 48% \t train_loss: 4.36 took: 0.48s\n",
            "Epoch 1, 60% \t train_loss: 4.25 took: 0.48s\n",
            "Epoch 1, 72% \t train_loss: 4.44 took: 0.47s\n",
            "Epoch 1, 84% \t train_loss: 4.61 took: 0.48s\n",
            "Epoch 1, 96% \t train_loss: 5.12 took: 0.47s\n",
            "Validation loss = 4.02\n",
            "Epoch 2, 12% \t train_loss: 4.64 took: 0.66s\n",
            "Epoch 2, 24% \t train_loss: 4.46 took: 0.48s\n",
            "Epoch 2, 36% \t train_loss: 4.23 took: 0.48s\n",
            "Epoch 2, 48% \t train_loss: 4.41 took: 0.47s\n",
            "Epoch 2, 60% \t train_loss: 4.32 took: 0.48s\n",
            "Epoch 2, 72% \t train_loss: 4.32 took: 0.47s\n",
            "Epoch 2, 84% \t train_loss: 7.82 took: 0.48s\n",
            "Epoch 2, 96% \t train_loss: 4.94 took: 0.47s\n",
            "Validation loss = 3.58\n",
            "Epoch 3, 12% \t train_loss: 4.20 took: 0.66s\n",
            "Epoch 3, 24% \t train_loss: 4.10 took: 0.49s\n",
            "Epoch 3, 36% \t train_loss: 4.08 took: 0.48s\n",
            "Epoch 3, 48% \t train_loss: 4.05 took: 0.49s\n",
            "Epoch 3, 60% \t train_loss: 4.08 took: 0.48s\n",
            "Epoch 3, 72% \t train_loss: 3.96 took: 0.48s\n",
            "Epoch 3, 84% \t train_loss: 4.38 took: 0.48s\n",
            "Epoch 3, 96% \t train_loss: 3.87 took: 0.49s\n",
            "Validation loss = 3.13\n",
            "Epoch 4, 12% \t train_loss: 3.73 took: 0.67s\n",
            "Epoch 4, 24% \t train_loss: 3.52 took: 0.48s\n",
            "Epoch 4, 36% \t train_loss: 3.87 took: 0.49s\n",
            "Epoch 4, 48% \t train_loss: 3.75 took: 0.49s\n",
            "Epoch 4, 60% \t train_loss: 3.54 took: 0.49s\n",
            "Epoch 4, 72% \t train_loss: 3.68 took: 0.49s\n",
            "Epoch 4, 84% \t train_loss: 4.56 took: 0.49s\n",
            "Epoch 4, 96% \t train_loss: 3.55 took: 0.49s\n",
            "Validation loss = 2.95\n",
            "Epoch 5, 12% \t train_loss: 3.51 took: 0.67s\n",
            "Epoch 5, 24% \t train_loss: 3.48 took: 0.50s\n",
            "Epoch 5, 36% \t train_loss: 3.47 took: 0.49s\n",
            "Epoch 5, 48% \t train_loss: 3.41 took: 0.49s\n",
            "Epoch 5, 60% \t train_loss: 3.37 took: 0.48s\n",
            "Epoch 5, 72% \t train_loss: 3.39 took: 0.50s\n",
            "Epoch 5, 84% \t train_loss: 3.36 took: 0.49s\n",
            "Epoch 5, 96% \t train_loss: 3.60 took: 0.50s\n",
            "Validation loss = 2.77\n",
            "Epoch 6, 12% \t train_loss: 3.29 took: 0.67s\n",
            "Epoch 6, 24% \t train_loss: 3.25 took: 0.49s\n",
            "Epoch 6, 36% \t train_loss: 3.24 took: 0.50s\n",
            "Epoch 6, 48% \t train_loss: 3.25 took: 0.51s\n",
            "Epoch 6, 60% \t train_loss: 3.21 took: 0.50s\n",
            "Epoch 6, 72% \t train_loss: 3.21 took: 0.49s\n",
            "Epoch 6, 84% \t train_loss: 3.22 took: 0.51s\n",
            "Epoch 6, 96% \t train_loss: 3.16 took: 0.50s\n",
            "Validation loss = 2.66\n",
            "Epoch 7, 12% \t train_loss: 3.16 took: 0.70s\n",
            "Epoch 7, 24% \t train_loss: 3.18 took: 0.51s\n",
            "Epoch 7, 36% \t train_loss: 3.11 took: 0.50s\n",
            "Epoch 7, 48% \t train_loss: 3.11 took: 0.51s\n",
            "Epoch 7, 60% \t train_loss: 3.10 took: 0.51s\n",
            "Epoch 7, 72% \t train_loss: 3.11 took: 0.51s\n",
            "Epoch 7, 84% \t train_loss: 3.08 took: 0.51s\n",
            "Epoch 7, 96% \t train_loss: 3.08 took: 0.52s\n",
            "Validation loss = 2.56\n",
            "Epoch 8, 12% \t train_loss: 3.05 took: 0.70s\n",
            "Epoch 8, 24% \t train_loss: 3.07 took: 0.53s\n",
            "Epoch 8, 36% \t train_loss: 3.06 took: 0.55s\n",
            "Epoch 8, 48% \t train_loss: 3.05 took: 0.53s\n",
            "Epoch 8, 60% \t train_loss: 3.04 took: 0.54s\n",
            "Epoch 8, 72% \t train_loss: 3.07 took: 0.54s\n",
            "Epoch 8, 84% \t train_loss: 2.99 took: 0.54s\n",
            "Epoch 8, 96% \t train_loss: 2.98 took: 0.54s\n",
            "Validation loss = 2.50\n",
            "Epoch 9, 12% \t train_loss: 3.00 took: 0.74s\n",
            "Epoch 9, 24% \t train_loss: 3.00 took: 0.55s\n",
            "Epoch 9, 36% \t train_loss: 2.99 took: 0.57s\n",
            "Epoch 9, 48% \t train_loss: 2.98 took: 0.55s\n",
            "Epoch 9, 60% \t train_loss: 2.98 took: 0.57s\n",
            "Epoch 9, 72% \t train_loss: 2.96 took: 0.56s\n",
            "Epoch 9, 84% \t train_loss: 2.98 took: 0.57s\n",
            "Epoch 9, 96% \t train_loss: 3.00 took: 0.58s\n",
            "Validation loss = 2.49\n",
            "Epoch 10, 12% \t train_loss: 2.96 took: 0.76s\n",
            "Epoch 10, 24% \t train_loss: 3.00 took: 0.58s\n",
            "Epoch 10, 36% \t train_loss: 2.93 took: 0.59s\n",
            "Epoch 10, 48% \t train_loss: 2.98 took: 0.59s\n",
            "Epoch 10, 60% \t train_loss: 2.94 took: 0.59s\n",
            "Epoch 10, 72% \t train_loss: 2.90 took: 0.60s\n",
            "Epoch 10, 84% \t train_loss: 2.95 took: 0.60s\n",
            "Epoch 10, 96% \t train_loss: 2.93 took: 0.61s\n",
            "Validation loss = 2.44\n",
            "Training finished, took 46.99s\n",
            "Testing Loss for model 1552915410.2281828 : 2.4411017179489134\n",
            "===== HYPERPARAMETERS =====\n",
            "batch_size= 10\n",
            "epochs= 10\n",
            "learning_rate= 0.01\n",
            "==============================\n",
            "Epoch 1, 12% \t train_loss: 16.27 took: 0.63s\n",
            "Epoch 1, 24% \t train_loss: 4.60 took: 0.44s\n",
            "Epoch 1, 36% \t train_loss: 5.27 took: 0.44s\n",
            "Epoch 1, 48% \t train_loss: 4.34 took: 0.44s\n",
            "Epoch 1, 60% \t train_loss: 4.62 took: 0.44s\n",
            "Epoch 1, 72% \t train_loss: 4.19 took: 0.43s\n",
            "Epoch 1, 84% \t train_loss: 4.27 took: 0.43s\n",
            "Epoch 1, 96% \t train_loss: 4.04 took: 0.44s\n",
            "Validation loss = 3.84\n",
            "Epoch 2, 12% \t train_loss: 3.99 took: 0.62s\n",
            "Epoch 2, 24% \t train_loss: 3.96 took: 0.43s\n",
            "Epoch 2, 36% \t train_loss: 4.41 took: 0.44s\n",
            "Epoch 2, 48% \t train_loss: 3.83 took: 0.43s\n",
            "Epoch 2, 60% \t train_loss: 3.73 took: 0.43s\n",
            "Epoch 2, 72% \t train_loss: 3.94 took: 0.43s\n",
            "Epoch 2, 84% \t train_loss: 3.80 took: 0.43s\n",
            "Epoch 2, 96% \t train_loss: 5.06 took: 0.43s\n",
            "Validation loss = 3.22\n",
            "Epoch 3, 12% \t train_loss: 3.94 took: 0.61s\n",
            "Epoch 3, 24% \t train_loss: 3.75 took: 0.43s\n",
            "Epoch 3, 36% \t train_loss: 3.57 took: 0.43s\n",
            "Epoch 3, 48% \t train_loss: 4.40 took: 0.43s\n",
            "Epoch 3, 60% \t train_loss: 3.67 took: 0.43s\n",
            "Epoch 3, 72% \t train_loss: 3.93 took: 0.43s\n",
            "Epoch 3, 84% \t train_loss: 4.31 took: 0.42s\n",
            "Epoch 3, 96% \t train_loss: 3.14 took: 0.43s\n",
            "Validation loss = 2.91\n",
            "Epoch 4, 12% \t train_loss: 3.48 took: 0.61s\n",
            "Epoch 4, 24% \t train_loss: 3.66 took: 0.43s\n",
            "Epoch 4, 36% \t train_loss: 3.61 took: 0.44s\n",
            "Epoch 4, 48% \t train_loss: 3.33 took: 0.44s\n",
            "Epoch 4, 60% \t train_loss: 3.58 took: 0.43s\n",
            "Epoch 4, 72% \t train_loss: 3.54 took: 0.44s\n",
            "Epoch 4, 84% \t train_loss: 3.77 took: 0.44s\n",
            "Epoch 4, 96% \t train_loss: 3.44 took: 0.44s\n",
            "Validation loss = 2.70\n",
            "Epoch 5, 12% \t train_loss: 3.46 took: 0.61s\n",
            "Epoch 5, 24% \t train_loss: 3.67 took: 0.43s\n",
            "Epoch 5, 36% \t train_loss: 3.44 took: 0.44s\n",
            "Epoch 5, 48% \t train_loss: 3.29 took: 0.43s\n",
            "Epoch 5, 60% \t train_loss: 3.38 took: 0.43s\n",
            "Epoch 5, 72% \t train_loss: 3.25 took: 0.44s\n",
            "Epoch 5, 84% \t train_loss: 3.48 took: 0.43s\n",
            "Epoch 5, 96% \t train_loss: 3.06 took: 0.43s\n",
            "Validation loss = 2.60\n",
            "Epoch 6, 12% \t train_loss: 3.11 took: 0.61s\n",
            "Epoch 6, 24% \t train_loss: 3.16 took: 0.43s\n",
            "Epoch 6, 36% \t train_loss: 3.11 took: 0.44s\n",
            "Epoch 6, 48% \t train_loss: 3.04 took: 0.44s\n",
            "Epoch 6, 60% \t train_loss: 3.08 took: 0.44s\n",
            "Epoch 6, 72% \t train_loss: 3.05 took: 0.44s\n",
            "Epoch 6, 84% \t train_loss: 3.21 took: 0.43s\n",
            "Epoch 6, 96% \t train_loss: 2.94 took: 0.44s\n",
            "Validation loss = 2.53\n",
            "Epoch 7, 12% \t train_loss: 3.04 took: 0.61s\n",
            "Epoch 7, 24% \t train_loss: 3.11 took: 0.43s\n",
            "Epoch 7, 36% \t train_loss: 2.99 took: 0.44s\n",
            "Epoch 7, 48% \t train_loss: 3.32 took: 0.44s\n",
            "Epoch 7, 60% \t train_loss: 3.22 took: 0.44s\n",
            "Epoch 7, 72% \t train_loss: 3.05 took: 0.44s\n",
            "Epoch 7, 84% \t train_loss: 4.00 took: 0.44s\n",
            "Epoch 7, 96% \t train_loss: 3.13 took: 0.44s\n",
            "Validation loss = 2.71\n",
            "Epoch 8, 12% \t train_loss: 3.30 took: 0.62s\n",
            "Epoch 8, 24% \t train_loss: 3.22 took: 0.43s\n",
            "Epoch 8, 36% \t train_loss: 3.21 took: 0.44s\n",
            "Epoch 8, 48% \t train_loss: 3.20 took: 0.44s\n",
            "Epoch 8, 60% \t train_loss: 3.16 took: 0.44s\n",
            "Epoch 8, 72% \t train_loss: 3.16 took: 0.45s\n",
            "Epoch 8, 84% \t train_loss: 3.15 took: 0.44s\n",
            "Epoch 8, 96% \t train_loss: 3.10 took: 0.44s\n",
            "Validation loss = 2.63\n",
            "Epoch 9, 12% \t train_loss: 3.08 took: 0.62s\n",
            "Epoch 9, 24% \t train_loss: 3.09 took: 0.44s\n",
            "Epoch 9, 36% \t train_loss: 3.11 took: 0.45s\n",
            "Epoch 9, 48% \t train_loss: 3.08 took: 0.45s\n",
            "Epoch 9, 60% \t train_loss: 3.12 took: 0.44s\n",
            "Epoch 9, 72% \t train_loss: 3.09 took: 0.45s\n",
            "Epoch 9, 84% \t train_loss: 3.09 took: 0.46s\n",
            "Epoch 9, 96% \t train_loss: 3.00 took: 0.46s\n",
            "Validation loss = 2.53\n",
            "Epoch 10, 12% \t train_loss: 3.04 took: 0.64s\n",
            "Epoch 10, 24% \t train_loss: 3.01 took: 0.46s\n",
            "Epoch 10, 36% \t train_loss: 2.98 took: 0.47s\n",
            "Epoch 10, 48% \t train_loss: 2.95 took: 0.47s\n",
            "Epoch 10, 60% \t train_loss: 3.39 took: 0.47s\n",
            "Epoch 10, 72% \t train_loss: 3.00 took: 0.47s\n",
            "Epoch 10, 84% \t train_loss: 2.98 took: 0.48s\n",
            "Epoch 10, 96% \t train_loss: 2.99 took: 0.48s\n",
            "Validation loss = 2.47\n",
            "Training finished, took 40.94s\n",
            "Testing Loss for model 1552915410.2901597 : 2.471049690246582\n",
            "===== HYPERPARAMETERS =====\n",
            "batch_size= 10\n",
            "epochs= 10\n",
            "learning_rate= 0.01\n",
            "==============================\n",
            "Epoch 1, 12% \t train_loss: 783.20 took: 0.56s\n",
            "Epoch 1, 24% \t train_loss: 696.20 took: 0.39s\n",
            "Epoch 1, 36% \t train_loss: 530.20 took: 0.38s\n",
            "Epoch 1, 48% \t train_loss: 643.51 took: 0.38s\n",
            "Epoch 1, 60% \t train_loss: 463.43 took: 0.37s\n",
            "Epoch 1, 72% \t train_loss: 514.15 took: 0.37s\n",
            "Epoch 1, 84% \t train_loss: 408.37 took: 0.37s\n",
            "Epoch 1, 96% \t train_loss: 370.41 took: 0.36s\n",
            "Validation loss = 446.28\n",
            "Epoch 2, 12% \t train_loss: 508.10 took: 0.54s\n",
            "Epoch 2, 24% \t train_loss: 437.06 took: 0.36s\n",
            "Epoch 2, 36% \t train_loss: 299.08 took: 0.36s\n",
            "Epoch 2, 48% \t train_loss: 309.69 took: 0.37s\n",
            "Epoch 2, 60% \t train_loss: 413.19 took: 0.36s\n",
            "Epoch 2, 72% \t train_loss: 337.44 took: 0.36s\n",
            "Epoch 2, 84% \t train_loss: 351.45 took: 0.36s\n",
            "Epoch 2, 96% \t train_loss: 419.54 took: 0.36s\n",
            "Validation loss = 294.90\n",
            "Epoch 3, 12% \t train_loss: 344.45 took: 0.54s\n",
            "Epoch 3, 24% \t train_loss: 453.33 took: 0.37s\n",
            "Epoch 3, 36% \t train_loss: 409.11 took: 0.37s\n",
            "Epoch 3, 48% \t train_loss: 470.41 took: 0.37s\n",
            "Epoch 3, 60% \t train_loss: 389.72 took: 0.37s\n",
            "Epoch 3, 72% \t train_loss: 457.64 took: 0.36s\n",
            "Epoch 3, 84% \t train_loss: 477.88 took: 0.37s\n",
            "Epoch 3, 96% \t train_loss: 402.64 took: 0.36s\n",
            "Validation loss = 361.60\n",
            "Epoch 4, 12% \t train_loss: 515.58 took: 0.53s\n",
            "Epoch 4, 24% \t train_loss: 515.53 took: 0.37s\n",
            "Epoch 4, 36% \t train_loss: 593.37 took: 0.36s\n",
            "Epoch 4, 48% \t train_loss: 766.89 took: 0.35s\n",
            "Epoch 4, 60% \t train_loss: 669.78 took: 0.36s\n",
            "Epoch 4, 72% \t train_loss: 700.54 took: 0.36s\n",
            "Epoch 4, 84% \t train_loss: 726.00 took: 0.35s\n",
            "Epoch 4, 96% \t train_loss: 992.12 took: 0.36s\n",
            "Validation loss = 664.38\n",
            "Epoch 5, 12% \t train_loss: 890.59 took: 0.53s\n",
            "Epoch 5, 24% \t train_loss: 1089.33 took: 0.36s\n",
            "Epoch 5, 36% \t train_loss: 909.39 took: 0.36s\n",
            "Epoch 5, 48% \t train_loss: 1047.08 took: 0.36s\n",
            "Epoch 5, 60% \t train_loss: 1339.74 took: 0.36s\n",
            "Epoch 5, 72% \t train_loss: 1214.34 took: 0.35s\n",
            "Epoch 5, 84% \t train_loss: 1412.82 took: 0.36s\n",
            "Epoch 5, 96% \t train_loss: 1787.95 took: 0.37s\n",
            "Validation loss = 1369.69\n",
            "Epoch 6, 12% \t train_loss: 1666.35 took: 0.54s\n",
            "Epoch 6, 24% \t train_loss: 2258.75 took: 0.35s\n",
            "Epoch 6, 36% \t train_loss: 2535.29 took: 0.36s\n",
            "Epoch 6, 48% \t train_loss: 2548.23 took: 0.36s\n",
            "Epoch 6, 60% \t train_loss: 2137.89 took: 0.35s\n",
            "Epoch 6, 72% \t train_loss: 2534.69 took: 0.36s\n",
            "Epoch 6, 84% \t train_loss: 2257.42 took: 0.36s\n",
            "Epoch 6, 96% \t train_loss: 3459.19 took: 0.35s\n",
            "Validation loss = 2526.63\n",
            "Epoch 7, 12% \t train_loss: 2666.58 took: 0.53s\n",
            "Epoch 7, 24% \t train_loss: 3186.50 took: 0.36s\n",
            "Epoch 7, 36% \t train_loss: 3057.08 took: 0.36s\n",
            "Epoch 7, 48% \t train_loss: 3025.39 took: 0.35s\n",
            "Epoch 7, 60% \t train_loss: 3639.08 took: 0.36s\n",
            "Epoch 7, 72% \t train_loss: 3088.60 took: 0.35s\n",
            "Epoch 7, 84% \t train_loss: 2974.65 took: 0.36s\n",
            "Epoch 7, 96% \t train_loss: 3886.48 took: 0.35s\n",
            "Validation loss = 3552.00\n",
            "Epoch 8, 12% \t train_loss: 4404.56 took: 0.53s\n",
            "Epoch 8, 24% \t train_loss: 4836.17 took: 0.36s\n",
            "Epoch 8, 36% \t train_loss: 3307.61 took: 0.35s\n",
            "Epoch 8, 48% \t train_loss: 3368.55 took: 0.35s\n",
            "Epoch 8, 60% \t train_loss: 3138.76 took: 0.36s\n",
            "Epoch 8, 72% \t train_loss: 3109.77 took: 0.35s\n",
            "Epoch 8, 84% \t train_loss: 3836.21 took: 0.36s\n",
            "Epoch 8, 96% \t train_loss: 3361.35 took: 0.35s\n",
            "Validation loss = 3584.53\n",
            "Epoch 9, 12% \t train_loss: 3903.99 took: 0.54s\n",
            "Epoch 9, 24% \t train_loss: 3153.33 took: 0.35s\n",
            "Epoch 9, 36% \t train_loss: 3270.56 took: 0.36s\n",
            "Epoch 9, 48% \t train_loss: 2956.18 took: 0.35s\n",
            "Epoch 9, 60% \t train_loss: 2505.93 took: 0.35s\n",
            "Epoch 9, 72% \t train_loss: 3570.74 took: 0.36s\n",
            "Epoch 9, 84% \t train_loss: 3482.63 took: 0.36s\n",
            "Epoch 9, 96% \t train_loss: 3667.99 took: 0.35s\n",
            "Validation loss = 3001.18\n",
            "Epoch 10, 12% \t train_loss: 3704.98 took: 0.52s\n",
            "Epoch 10, 24% \t train_loss: 3287.66 took: 0.35s\n",
            "Epoch 10, 36% \t train_loss: 3673.12 took: 0.36s\n",
            "Epoch 10, 48% \t train_loss: 2887.89 took: 0.35s\n",
            "Epoch 10, 60% \t train_loss: 3407.87 took: 0.36s\n",
            "Epoch 10, 72% \t train_loss: 3337.15 took: 0.36s\n",
            "Epoch 10, 84% \t train_loss: 2998.60 took: 0.35s\n",
            "Epoch 10, 96% \t train_loss: 3390.32 took: 0.35s\n",
            "Validation loss = 2683.72\n",
            "Training finished, took 34.11s\n",
            "Testing Loss for model 1552915410.3738916 : 2954.445166015625\n",
            "===== HYPERPARAMETERS =====\n",
            "batch_size= 10\n",
            "epochs= 10\n",
            "learning_rate= 0.01\n",
            "==============================\n",
            "Epoch 1, 12% \t train_loss: 6.60 took: 5.51s\n",
            "Epoch 1, 24% \t train_loss: 5.79 took: 4.81s\n",
            "Epoch 1, 36% \t train_loss: 5.18 took: 4.86s\n",
            "Epoch 1, 48% \t train_loss: 4.20 took: 4.86s\n",
            "Epoch 1, 60% \t train_loss: 4.73 took: 4.87s\n",
            "Epoch 1, 72% \t train_loss: 3.51 took: 4.84s\n",
            "Epoch 1, 84% \t train_loss: 4.38 took: 4.87s\n",
            "Epoch 1, 96% \t train_loss: 3.36 took: 4.93s\n",
            "Validation loss = 2.60\n",
            "Epoch 2, 12% \t train_loss: 3.04 took: 5.84s\n",
            "Epoch 2, 24% \t train_loss: 3.10 took: 4.81s\n",
            "Epoch 2, 36% \t train_loss: 3.33 took: 4.81s\n",
            "Epoch 2, 48% \t train_loss: 3.09 took: 4.83s\n",
            "Epoch 2, 60% \t train_loss: 3.00 took: 4.81s\n",
            "Epoch 2, 72% \t train_loss: 2.94 took: 4.83s\n",
            "Epoch 2, 84% \t train_loss: 3.05 took: 4.81s\n",
            "Epoch 2, 96% \t train_loss: 2.86 took: 4.81s\n",
            "Validation loss = 2.47\n",
            "Epoch 3, 12% \t train_loss: 2.95 took: 5.80s\n",
            "Epoch 3, 24% \t train_loss: 2.85 took: 4.80s\n",
            "Epoch 3, 36% \t train_loss: 2.91 took: 4.81s\n",
            "Epoch 3, 48% \t train_loss: 3.04 took: 4.81s\n",
            "Epoch 3, 60% \t train_loss: 2.95 took: 4.80s\n",
            "Epoch 3, 72% \t train_loss: 2.89 took: 4.80s\n",
            "Epoch 3, 84% \t train_loss: 2.91 took: 4.80s\n",
            "Epoch 3, 96% \t train_loss: 2.92 took: 4.81s\n",
            "Validation loss = 2.47\n",
            "Epoch 4, 12% \t train_loss: 2.92 took: 5.85s\n",
            "Epoch 4, 24% \t train_loss: 2.91 took: 4.83s\n",
            "Epoch 4, 36% \t train_loss: 2.89 took: 4.80s\n",
            "Epoch 4, 48% \t train_loss: 3.05 took: 4.79s\n",
            "Epoch 4, 60% \t train_loss: 2.88 took: 4.83s\n",
            "Epoch 4, 72% \t train_loss: 3.13 took: 4.84s\n",
            "Epoch 4, 84% \t train_loss: 2.92 took: 4.85s\n",
            "Epoch 4, 96% \t train_loss: 3.06 took: 4.90s\n",
            "Validation loss = 2.43\n",
            "Epoch 5, 12% \t train_loss: 2.90 took: 5.79s\n",
            "Epoch 5, 24% \t train_loss: 2.91 took: 4.77s\n",
            "Epoch 5, 36% \t train_loss: 2.94 took: 4.78s\n",
            "Epoch 5, 48% \t train_loss: 2.94 took: 4.78s\n",
            "Epoch 5, 60% \t train_loss: 2.87 took: 4.79s\n",
            "Epoch 5, 72% \t train_loss: 2.89 took: 4.79s\n",
            "Epoch 5, 84% \t train_loss: 2.90 took: 4.79s\n",
            "Epoch 5, 96% \t train_loss: 2.94 took: 4.77s\n",
            "Validation loss = 2.41\n",
            "Epoch 6, 12% \t train_loss: 2.77 took: 5.81s\n",
            "Epoch 6, 24% \t train_loss: 3.10 took: 4.80s\n",
            "Epoch 6, 36% \t train_loss: 2.97 took: 4.75s\n",
            "Epoch 6, 48% \t train_loss: 2.93 took: 4.77s\n",
            "Epoch 6, 60% \t train_loss: 2.97 took: 4.77s\n",
            "Epoch 6, 72% \t train_loss: 2.85 took: 4.76s\n",
            "Epoch 6, 84% \t train_loss: 2.89 took: 4.77s\n",
            "Epoch 6, 96% \t train_loss: 2.89 took: 4.76s\n",
            "Validation loss = 2.51\n",
            "Epoch 7, 12% \t train_loss: 2.91 took: 5.76s\n",
            "Epoch 7, 24% \t train_loss: 2.83 took: 4.75s\n",
            "Epoch 7, 36% \t train_loss: 2.95 took: 4.78s\n",
            "Epoch 7, 48% \t train_loss: 3.01 took: 4.76s\n",
            "Epoch 7, 60% \t train_loss: 2.93 took: 4.77s\n",
            "Epoch 7, 72% \t train_loss: 2.94 took: 4.78s\n",
            "Epoch 7, 84% \t train_loss: 2.90 took: 4.77s\n",
            "Epoch 7, 96% \t train_loss: 2.91 took: 4.77s\n",
            "Validation loss = 2.41\n",
            "Epoch 8, 12% \t train_loss: 2.90 took: 5.78s\n",
            "Epoch 8, 24% \t train_loss: 2.91 took: 4.77s\n",
            "Epoch 8, 36% \t train_loss: 2.87 took: 4.77s\n",
            "Epoch 8, 48% \t train_loss: 2.92 took: 4.78s\n",
            "Epoch 8, 60% \t train_loss: 2.81 took: 4.75s\n",
            "Epoch 8, 72% \t train_loss: 2.94 took: 4.76s\n",
            "Epoch 8, 84% \t train_loss: 2.94 took: 4.76s\n",
            "Epoch 8, 96% \t train_loss: 2.83 took: 4.74s\n",
            "Validation loss = 2.40\n",
            "Epoch 9, 12% \t train_loss: 2.88 took: 5.77s\n",
            "Epoch 9, 24% \t train_loss: 2.92 took: 4.78s\n",
            "Epoch 9, 36% \t train_loss: 2.92 took: 4.76s\n",
            "Epoch 9, 48% \t train_loss: 2.81 took: 4.77s\n",
            "Epoch 9, 60% \t train_loss: 2.77 took: 4.76s\n",
            "Epoch 9, 72% \t train_loss: 2.89 took: 4.76s\n",
            "Epoch 9, 84% \t train_loss: 2.92 took: 4.76s\n",
            "Epoch 9, 96% \t train_loss: 2.91 took: 4.79s\n",
            "Validation loss = 2.35\n",
            "Epoch 10, 12% \t train_loss: 2.88 took: 5.79s\n",
            "Epoch 10, 24% \t train_loss: 2.80 took: 4.75s\n",
            "Epoch 10, 36% \t train_loss: 2.83 took: 4.75s\n",
            "Epoch 10, 48% \t train_loss: 2.82 took: 4.77s\n",
            "Epoch 10, 60% \t train_loss: 2.85 took: 4.75s\n",
            "Epoch 10, 72% \t train_loss: 2.77 took: 4.78s\n",
            "Epoch 10, 84% \t train_loss: 2.95 took: 4.75s\n",
            "Epoch 10, 96% \t train_loss: 2.92 took: 4.76s\n",
            "Validation loss = 2.42\n",
            "Training finished, took 415.17s\n",
            "Testing Loss for model 1552915410.4308813 : 2.366335082054138\n",
            "===== HYPERPARAMETERS =====\n",
            "batch_size= 10\n",
            "epochs= 10\n",
            "learning_rate= 0.01\n",
            "==============================\n",
            "Epoch 1, 12% \t train_loss: 4.99 took: 6.30s\n",
            "Epoch 1, 24% \t train_loss: 4.50 took: 5.35s\n",
            "Epoch 1, 36% \t train_loss: 4.19 took: 5.39s\n",
            "Epoch 1, 48% \t train_loss: 3.75 took: 5.37s\n",
            "Epoch 1, 60% \t train_loss: 4.18 took: 5.41s\n",
            "Epoch 1, 72% \t train_loss: 3.68 took: 5.40s\n",
            "Epoch 1, 84% \t train_loss: 3.65 took: 5.42s\n",
            "Epoch 1, 96% \t train_loss: 4.27 took: 5.42s\n",
            "Validation loss = 3.11\n",
            "Epoch 2, 12% \t train_loss: 3.63 took: 6.51s\n",
            "Epoch 2, 24% \t train_loss: 3.74 took: 5.44s\n",
            "Epoch 2, 36% \t train_loss: 3.79 took: 5.46s\n",
            "Epoch 2, 48% \t train_loss: 3.53 took: 5.43s\n",
            "Epoch 2, 60% \t train_loss: 3.94 took: 5.42s\n",
            "Epoch 2, 72% \t train_loss: 3.91 took: 5.40s\n",
            "Epoch 2, 84% \t train_loss: 3.75 took: 5.43s\n",
            "Epoch 2, 96% \t train_loss: 4.05 took: 5.42s\n",
            "Validation loss = 3.42\n",
            "Epoch 3, 12% \t train_loss: 3.84 took: 6.42s\n",
            "Epoch 3, 24% \t train_loss: 3.72 took: 5.40s\n",
            "Epoch 3, 36% \t train_loss: 3.79 took: 5.38s\n",
            "Epoch 3, 48% \t train_loss: 3.75 took: 5.39s\n",
            "Epoch 3, 60% \t train_loss: 3.62 took: 5.38s\n",
            "Epoch 3, 72% \t train_loss: 3.59 took: 5.40s\n",
            "Epoch 3, 84% \t train_loss: 3.92 took: 5.38s\n",
            "Epoch 3, 96% \t train_loss: 3.47 took: 5.39s\n",
            "Validation loss = 3.10\n",
            "Epoch 4, 12% \t train_loss: 3.86 took: 6.45s\n",
            "Epoch 4, 24% \t train_loss: 3.73 took: 5.43s\n",
            "Epoch 4, 36% \t train_loss: 3.56 took: 5.41s\n",
            "Epoch 4, 48% \t train_loss: 3.78 took: 5.44s\n",
            "Epoch 4, 60% \t train_loss: 3.85 took: 5.45s\n",
            "Epoch 4, 72% \t train_loss: 3.82 took: 5.41s\n",
            "Epoch 4, 84% \t train_loss: 3.83 took: 5.42s\n",
            "Epoch 4, 96% \t train_loss: 4.07 took: 5.44s\n",
            "Validation loss = 3.15\n",
            "Epoch 5, 12% \t train_loss: 3.64 took: 6.35s\n",
            "Epoch 5, 24% \t train_loss: 4.11 took: 5.36s\n",
            "Epoch 5, 36% \t train_loss: 3.55 took: 5.43s\n",
            "Epoch 5, 48% \t train_loss: 3.96 took: 5.37s\n",
            "Epoch 5, 60% \t train_loss: 4.22 took: 5.34s\n",
            "Epoch 5, 72% \t train_loss: 3.75 took: 5.38s\n",
            "Epoch 5, 84% \t train_loss: 3.56 took: 5.41s\n",
            "Epoch 5, 96% \t train_loss: 3.97 took: 5.36s\n",
            "Validation loss = 3.44\n",
            "Epoch 6, 12% \t train_loss: 3.93 took: 6.35s\n",
            "Epoch 6, 24% \t train_loss: 3.93 took: 5.36s\n",
            "Epoch 6, 36% \t train_loss: 4.66 took: 5.38s\n",
            "Epoch 6, 48% \t train_loss: 3.90 took: 5.38s\n",
            "Epoch 6, 60% \t train_loss: 4.10 took: 5.37s\n",
            "Epoch 6, 72% \t train_loss: 3.99 took: 5.41s\n",
            "Epoch 6, 84% \t train_loss: 4.02 took: 5.35s\n",
            "Epoch 6, 96% \t train_loss: 4.07 took: 5.38s\n",
            "Validation loss = 3.08\n",
            "Epoch 7, 12% \t train_loss: 3.88 took: 6.45s\n",
            "Epoch 7, 24% \t train_loss: 3.61 took: 5.47s\n",
            "Epoch 7, 36% \t train_loss: 4.14 took: 5.44s\n",
            "Epoch 7, 48% \t train_loss: 3.64 took: 5.47s\n",
            "Epoch 7, 60% \t train_loss: 3.67 took: 5.47s\n",
            "Epoch 7, 72% \t train_loss: 4.11 took: 5.45s\n",
            "Epoch 7, 84% \t train_loss: 4.12 took: 5.45s\n",
            "Epoch 7, 96% \t train_loss: 3.60 took: 5.46s\n",
            "Validation loss = 3.14\n",
            "Epoch 8, 12% \t train_loss: 3.57 took: 6.45s\n",
            "Epoch 8, 24% \t train_loss: 3.74 took: 5.43s\n",
            "Epoch 8, 36% \t train_loss: 3.92 took: 5.49s\n",
            "Epoch 8, 48% \t train_loss: 4.25 took: 5.45s\n",
            "Epoch 8, 60% \t train_loss: 4.00 took: 5.46s\n",
            "Epoch 8, 72% \t train_loss: 3.79 took: 5.41s\n",
            "Epoch 8, 84% \t train_loss: 4.09 took: 5.40s\n",
            "Epoch 8, 96% \t train_loss: 3.83 took: 5.42s\n",
            "Validation loss = 3.84\n",
            "Epoch 9, 12% \t train_loss: 3.66 took: 6.41s\n",
            "Epoch 9, 24% \t train_loss: 4.00 took: 5.42s\n",
            "Epoch 9, 36% \t train_loss: 3.82 took: 5.43s\n",
            "Epoch 9, 48% \t train_loss: 3.72 took: 5.42s\n",
            "Epoch 9, 60% \t train_loss: 3.84 took: 5.44s\n",
            "Epoch 9, 72% \t train_loss: 3.56 took: 5.43s\n",
            "Epoch 9, 84% \t train_loss: 4.12 took: 5.42s\n",
            "Epoch 9, 96% \t train_loss: 3.99 took: 5.40s\n",
            "Validation loss = 4.22\n",
            "Epoch 10, 12% \t train_loss: 4.25 took: 6.40s\n",
            "Epoch 10, 24% \t train_loss: 4.17 took: 5.38s\n",
            "Epoch 10, 36% \t train_loss: 4.30 took: 5.42s\n",
            "Epoch 10, 48% \t train_loss: 4.29 took: 5.40s\n",
            "Epoch 10, 60% \t train_loss: 3.79 took: 5.41s\n",
            "Epoch 10, 72% \t train_loss: 4.05 took: 5.37s\n",
            "Epoch 10, 84% \t train_loss: 4.25 took: 5.42s\n",
            "Epoch 10, 96% \t train_loss: 4.16 took: 5.41s\n",
            "Validation loss = 3.31\n",
            "Training finished, took 466.97s\n",
            "Testing Loss for model 1552915411.0685484 : 3.223832631111145\n",
            "===== HYPERPARAMETERS =====\n",
            "batch_size= 10\n",
            "epochs= 10\n",
            "learning_rate= 0.01\n",
            "==============================\n",
            "Epoch 1, 12% \t train_loss: 4.85 took: 6.31s\n",
            "Epoch 1, 24% \t train_loss: 4.40 took: 5.40s\n",
            "Epoch 1, 36% \t train_loss: 3.94 took: 5.41s\n",
            "Epoch 1, 48% \t train_loss: 4.42 took: 5.39s\n",
            "Epoch 1, 60% \t train_loss: 3.85 took: 5.37s\n",
            "Epoch 1, 72% \t train_loss: 4.32 took: 5.43s\n",
            "Epoch 1, 84% \t train_loss: 3.82 took: 5.43s\n",
            "Epoch 1, 96% \t train_loss: 3.79 took: 5.43s\n",
            "Validation loss = 3.31\n",
            "Epoch 2, 12% \t train_loss: 4.14 took: 6.43s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yHfb1OnzktDB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}